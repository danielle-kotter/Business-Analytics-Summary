<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter - 7 Practical data science | Business Analytics - Cheatsheets &amp; Summary</title>
  <meta name="description" content="This is a summary of r code learned throughout several courses of my master in management." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter - 7 Practical data science | Business Analytics - Cheatsheets &amp; Summary" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a summary of r code learned throughout several courses of my master in management." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter - 7 Practical data science | Business Analytics - Cheatsheets &amp; Summary" />
  
  <meta name="twitter:description" content="This is a summary of r code learned throughout several courses of my master in management." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basics-python.html"/>
<link rel="next" href="advanced-statistical-methods.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">R-coding Cheatsheets & Summary</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="basics-r.html"><a href="basics-r.html"><i class="fa fa-check"></i><b>1</b> Basics R</a>
<ul>
<li class="chapter" data-level="1.0.1" data-path="basics-r.html"><a href="basics-r.html#tables-frames-matrices"><i class="fa fa-check"></i><b>1.0.1</b> Tables, frames &amp; Matrices</a></li>
<li class="chapter" data-level="1.1" data-path="basics-r.html"><a href="basics-r.html#data-sets"><i class="fa fa-check"></i><b>1.1</b> Data sets</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="basics-r.html"><a href="basics-r.html#removing-infinite-na-values"><i class="fa fa-check"></i><b>1.1.1</b> Removing infinite + NA values</a></li>
<li class="chapter" data-level="1.1.2" data-path="basics-r.html"><a href="basics-r.html#transforming-variable-types"><i class="fa fa-check"></i><b>1.1.2</b> Transforming variable types</a></li>
<li class="chapter" data-level="1.1.3" data-path="basics-r.html"><a href="basics-r.html#markdown"><i class="fa fa-check"></i><b>1.1.3</b> Markdown</a></li>
<li class="chapter" data-level="1.1.4" data-path="basics-r.html"><a href="basics-r.html#setup-rmarkdown-code-chunks"><i class="fa fa-check"></i><b>1.1.4</b> Setup rmarkdown &amp; code chunks</a></li>
<li class="chapter" data-level="1.1.5" data-path="basics-r.html"><a href="basics-r.html#latex"><i class="fa fa-check"></i><b>1.1.5</b> Latex</a></li>
<li class="chapter" data-level="1.1.6" data-path="basics-r.html"><a href="basics-r.html#miscellaneous"><i class="fa fa-check"></i><b>1.1.6</b> Miscellaneous</a></li>
<li class="chapter" data-level="1.1.7" data-path="basics-r.html"><a href="basics-r.html#subsetting"><i class="fa fa-check"></i><b>1.1.7</b> Subsetting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="charts-templates-r.html"><a href="charts-templates-r.html"><i class="fa fa-check"></i><b>2</b> Charts templates - R</a></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#bayes-theorem"><i class="fa fa-check"></i><b>3.1</b> Bayes Theorem</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#discrete-probablity"><i class="fa fa-check"></i><b>3.2</b> Discrete Probablity</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="probability.html"><a href="probability.html#uniform-discrete-probability-distribution"><i class="fa fa-check"></i><b>3.2.1</b> Uniform discrete probability distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="probability.html"><a href="probability.html#binomial-distribution"><i class="fa fa-check"></i><b>3.2.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.2.3" data-path="probability.html"><a href="probability.html#poisson-distribution"><i class="fa fa-check"></i><b>3.2.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="3.2.4" data-path="probability.html"><a href="probability.html#the-normal-distribution"><i class="fa fa-check"></i><b>3.2.4</b> The normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#samples-estimation-confidence-intervals"><i class="fa fa-check"></i><b>3.3</b> Samples, estimation &amp; confidence intervals</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#significance-level"><i class="fa fa-check"></i><b>3.4</b> Significance level</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probability.html"><a href="probability.html#critical-values"><i class="fa fa-check"></i><b>3.4.1</b> Critical values</a></li>
<li class="chapter" data-level="3.4.2" data-path="probability.html"><a href="probability.html#test-of-equality---two-samples"><i class="fa fa-check"></i><b>3.4.2</b> Test of equality - two samples</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#non-parametric-testing"><i class="fa fa-check"></i><b>3.5</b> Non-Parametric testing</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="probability.html"><a href="probability.html#contengency-table-frequencies"><i class="fa fa-check"></i><b>3.5.1</b> Contengency table / frequencies</a></li>
<li class="chapter" data-level="3.5.2" data-path="probability.html"><a href="probability.html#chi-square"><i class="fa fa-check"></i><b>3.5.2</b> Chi-square</a></li>
<li class="chapter" data-level="3.5.3" data-path="probability.html"><a href="probability.html#goodness-of-fit"><i class="fa fa-check"></i><b>3.5.3</b> Goodness of fit</a></li>
<li class="chapter" data-level="3.5.4" data-path="probability.html"><a href="probability.html#p-value"><i class="fa fa-check"></i><b>3.5.4</b> P-value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-regressions.html"><a href="simple-regressions.html"><i class="fa fa-check"></i><b>4</b> Simple regressions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-regressions.html"><a href="simple-regressions.html#basics-regressions"><i class="fa fa-check"></i><b>4.1</b> Basics regressions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="simple-regressions.html"><a href="simple-regressions.html#summarizing-regressions"><i class="fa fa-check"></i><b>4.1.1</b> Summarizing regressions:</a></li>
<li class="chapter" data-level="4.1.2" data-path="simple-regressions.html"><a href="simple-regressions.html#dummy-variables-diff-in-means"><i class="fa fa-check"></i><b>4.1.2</b> Dummy variables, diff in means</a></li>
<li class="chapter" data-level="4.1.3" data-path="simple-regressions.html"><a href="simple-regressions.html#regression-dummy"><i class="fa fa-check"></i><b>4.1.3</b> Regression + dummy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="simple-regressions.html"><a href="simple-regressions.html#prediction"><i class="fa fa-check"></i><b>4.2</b> Prediction</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="simple-regressions.html"><a href="simple-regressions.html#confidence-and-prediction-plotting"><i class="fa fa-check"></i><b>4.2.1</b> Confidence and prediction plotting</a></li>
<li class="chapter" data-level="4.2.2" data-path="simple-regressions.html"><a href="simple-regressions.html#prediction-with-dummy-variables"><i class="fa fa-check"></i><b>4.2.2</b> Prediction with dummy variables</a></li>
<li class="chapter" data-level="4.2.3" data-path="simple-regressions.html"><a href="simple-regressions.html#prediction-intervals-examples"><i class="fa fa-check"></i><b>4.2.3</b> Prediction intervals examples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="simple-regressions.html"><a href="simple-regressions.html#data-problems"><i class="fa fa-check"></i><b>4.3</b> Data problems</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="simple-regressions.html"><a href="simple-regressions.html#multicollinearity"><i class="fa fa-check"></i><b>4.3.1</b> Multicollinearity</a></li>
<li class="chapter" data-level="4.3.2" data-path="simple-regressions.html"><a href="simple-regressions.html#variance-inflation-factors"><i class="fa fa-check"></i><b>4.3.2</b> Variance inflation factors</a></li>
<li class="chapter" data-level="4.3.3" data-path="simple-regressions.html"><a href="simple-regressions.html#anova"><i class="fa fa-check"></i><b>4.3.3</b> ANOVA</a></li>
<li class="chapter" data-level="4.3.4" data-path="simple-regressions.html"><a href="simple-regressions.html#linearizing-variables"><i class="fa fa-check"></i><b>4.3.4</b> Linearizing variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="structure-equation-models.html"><a href="structure-equation-models.html"><i class="fa fa-check"></i><b>5</b> Structure equation models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="structure-equation-models.html"><a href="structure-equation-models.html#path-analysis-structural-equations"><i class="fa fa-check"></i><b>5.1</b> Path analysis (structural equations)</a></li>
<li class="chapter" data-level="5.2" data-path="structure-equation-models.html"><a href="structure-equation-models.html#coding-the-model"><i class="fa fa-check"></i><b>5.2</b> Coding the model</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="structure-equation-models.html"><a href="structure-equation-models.html#covariance"><i class="fa fa-check"></i><b>5.2.1</b> Covariance</a></li>
<li class="chapter" data-level="5.2.2" data-path="structure-equation-models.html"><a href="structure-equation-models.html#reliability"><i class="fa fa-check"></i><b>5.2.2</b> Reliability</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="structure-equation-models.html"><a href="structure-equation-models.html#factor-model"><i class="fa fa-check"></i><b>5.3</b> Factor model</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="structure-equation-models.html"><a href="structure-equation-models.html#setting-covariance-variances"><i class="fa fa-check"></i><b>5.3.1</b> Setting covariance &amp; variances</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basics-python.html"><a href="basics-python.html"><i class="fa fa-check"></i><b>6</b> Basics Python</a>
<ul>
<li class="chapter" data-level="6.1" data-path="basics-python.html"><a href="basics-python.html#data-set"><i class="fa fa-check"></i><b>6.1</b> Data set</a></li>
<li class="chapter" data-level="6.2" data-path="basics-python.html"><a href="basics-python.html#matrixes"><i class="fa fa-check"></i><b>6.2</b> Matrixes</a></li>
<li class="chapter" data-level="6.3" data-path="basics-python.html"><a href="basics-python.html#filtering-a-data-set"><i class="fa fa-check"></i><b>6.3</b> Filtering a data set</a></li>
<li class="chapter" data-level="6.4" data-path="basics-python.html"><a href="basics-python.html#data-imputation"><i class="fa fa-check"></i><b>6.4</b> Data imputation</a></li>
<li class="chapter" data-level="6.5" data-path="basics-python.html"><a href="basics-python.html#data-visualization"><i class="fa fa-check"></i><b>6.5</b> Data visualization</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="basics-python.html"><a href="basics-python.html#other-categorical-plots"><i class="fa fa-check"></i><b>6.5.1</b> Other categorical plots</a></li>
<li class="chapter" data-level="6.5.2" data-path="basics-python.html"><a href="basics-python.html#preparing-the-data"><i class="fa fa-check"></i><b>6.5.2</b> Preparing the data</a></li>
<li class="chapter" data-level="6.5.3" data-path="basics-python.html"><a href="basics-python.html#creating-the-models"><i class="fa fa-check"></i><b>6.5.3</b> Creating the models</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="basics-python.html"><a href="basics-python.html#model-selection"><i class="fa fa-check"></i><b>6.6</b> Model selection</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="practical-data-science.html"><a href="practical-data-science.html"><i class="fa fa-check"></i><b>7</b> Practical data science</a>
<ul>
<li class="chapter" data-level="7.1" data-path="practical-data-science.html"><a href="practical-data-science.html#machine-learning"><i class="fa fa-check"></i><b>7.1</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="practical-data-science.html"><a href="practical-data-science.html#theory"><i class="fa fa-check"></i><b>7.1.1</b> Theory</a></li>
<li class="chapter" data-level="7.1.2" data-path="practical-data-science.html"><a href="practical-data-science.html#finding-the-expected-value-of-the-error"><i class="fa fa-check"></i><b>7.1.2</b> Finding the expected value of the error</a></li>
<li class="chapter" data-level="7.1.3" data-path="practical-data-science.html"><a href="practical-data-science.html#loss-function"><i class="fa fa-check"></i><b>7.1.3</b> Loss function</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="practical-data-science.html"><a href="practical-data-science.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>7.2</b> Bias-variance trade off</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="practical-data-science.html"><a href="practical-data-science.html#training-fitting-a-model"><i class="fa fa-check"></i><b>7.2.1</b> Training (fitting) a model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="practical-data-science.html"><a href="practical-data-science.html#gradient-descent"><i class="fa fa-check"></i><b>7.3</b> Gradient descent</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="practical-data-science.html"><a href="practical-data-science.html#sarcastic-gradient-descent"><i class="fa fa-check"></i><b>7.3.1</b> Sarcastic gradient descent</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="practical-data-science.html"><a href="practical-data-science.html#model-selection-1"><i class="fa fa-check"></i><b>7.4</b> Model Selection</a></li>
<li class="chapter" data-level="7.5" data-path="practical-data-science.html"><a href="practical-data-science.html#classification-problems"><i class="fa fa-check"></i><b>7.5</b> Classification Problems</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="practical-data-science.html"><a href="practical-data-science.html#evaluating-model-quality"><i class="fa fa-check"></i><b>7.5.1</b> Evaluating model quality</a></li>
<li class="chapter" data-level="7.5.2" data-path="practical-data-science.html"><a href="practical-data-science.html#multi-class-classification"><i class="fa fa-check"></i><b>7.5.2</b> Multi-class classification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html"><i class="fa fa-check"></i><b>8</b> Advanced Statistical Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#clustering"><i class="fa fa-check"></i><b>8.1</b> Clustering</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#hierachical-clustering"><i class="fa fa-check"></i><b>8.1.1</b> Hierachical clustering</a></li>
<li class="chapter" data-level="8.1.2" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#non-hierachical-clustering"><i class="fa fa-check"></i><b>8.1.2</b> Non-Hierachical clustering</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#multi-dimensional-scaling"><i class="fa fa-check"></i><b>8.2</b> Multi-Dimensional Scaling</a></li>
<li class="chapter" data-level="8.3" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#principal-component-analysis"><i class="fa fa-check"></i><b>8.3</b> Principal component analysis</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#biplots"><i class="fa fa-check"></i><b>8.3.1</b> Biplots</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#correspondence-analysis"><i class="fa fa-check"></i><b>8.4</b> Correspondence analysis</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#multiple-correspondence-analysis"><i class="fa fa-check"></i><b>8.4.1</b> Multiple Correspondence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#multiple-linear-regression-classification-trees"><i class="fa fa-check"></i><b>8.5</b> Multiple linear regression &amp; classification trees</a></li>
<li class="chapter" data-level="8.6" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#text-analytics"><i class="fa fa-check"></i><b>8.6</b> Text analytics</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="marketing-analytics.html"><a href="marketing-analytics.html"><i class="fa fa-check"></i><b>9</b> Marketing Analytics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="marketing-analytics.html"><a href="marketing-analytics.html#logistic-regressions"><i class="fa fa-check"></i><b>9.1</b> Logistic regressions</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="marketing-analytics.html"><a href="marketing-analytics.html#sensitivity-vs-specificity"><i class="fa fa-check"></i><b>9.1.1</b> Sensitivity vs Specificity</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Business Analytics - Cheatsheets &amp; Summary</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="practical-data-science" class="section level1" number="7">
<h1><span class="header-section-number">Chapter - 7</span> Practical data science</h1>
<div id="machine-learning" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Machine Learning</h2>
<p>There are multiple types of machine learning:</p>
<ul>
<li><p>Supervised</p></li>
<li><p>Unsupervised</p></li>
<li><p>Reinforcement learning</p></li>
</ul>
<div id="reinforcement-learning" class="section level4" number="7.1.0.1">
<h4><span class="header-section-number">7.1.0.1</span> Reinforcement learning:</h4>
<p>Alpha go. ML for chess. Trained by trial and error. First they are
taught the simple rules and then asked to train by themselves and learn
from their mistakes. The algorithms are asked to do something and either</p>
<ul>
<li><p>Get a rewards or</p></li>
<li><p>A penalty</p></li>
</ul>
<p>As a result, they learn which moves are good and continue to try
something else. Machine learning still does not understand casual
relationships.</p>
</div>
<div id="unsupervised-learning" class="section level4" number="7.1.0.2">
<h4><span class="header-section-number">7.1.0.2</span> Unsupervised learning:</h4>
<p>We do not have labels on the data. Can still observe patterns, it
understands there are commonalities but not with a reason.</p>
<p>You can combine labeled data, for example from the passed and look for
patterns with the unlabeled data.</p>
<p><img src="images/paste-0F7C76CE.png" width="656" /></p>
</div>
<div id="supervised-learning" class="section level4" number="7.1.0.3">
<h4><span class="header-section-number">7.1.0.3</span> Supervised learning</h4>
<p>Supervised learning: Extracting patterns from data and making
predictions based on passed behavior.</p>
<p>An example is a picture of an animal and the algorithms predicts which
animal it is.</p>
<p>Hereby we use training data to train the algorithm. However, the data
must be labeled: we already know the correct answer. This method does
not include trial or error.</p>
<p>For example, first showing examples of cats and then it can make
predictions. Meaning, we show a new picture and it can predict whether
it is a cat or not a cat.</p>
<ul>
<li><p>Regression tasks: label is a continuous number. Hereby what we want
to predict is continuous, not necessarily the data given to predict.
F.E. House prices</p></li>
<li><p>Classification tasks: Label is one of discrete set of possible
values. F.E. Is it a dog or a cat</p></li>
</ul>
</div>
<div id="theory" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Theory</h3>
<p>Supervised learning - Regression - Classification</p>
<table style="width:97%;">
<colgroup>
<col width="22%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th>Symbol</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>y</td>
<td>Real value</td>
</tr>
<tr class="even">
<td><strong>ŷ</strong></td>
<td>Prediction</td>
</tr>
<tr class="odd">
<td><strong>y-ŷ</strong></td>
<td>Absolute error</td>
</tr>
<tr class="even">
<td><strong>( y-ŷ)^2</strong></td>
<td>Squared error |</td>
</tr>
<tr class="odd">
<td><strong>x</strong></td>
<td><p>Generic input / Features. The things I use to
predict y.</p>
<p>The independent variable (statistics).</p></td>
</tr>
<tr class="even">
<td><strong>y</strong></td>
<td><p>Generic output. The label. (ML) The thing I want to
predict.</p>
<p>Dependent variable (statistics).</p></td>
</tr>
<tr class="odd">
<td><strong>p</strong></td>
<td><p>Number of features (machine learning).</p>
<p>Number of independent variables I have
(statistics).</p></td>
</tr>
<tr class="even">
<td><strong>n</strong></td>
<td>Size of the data set</td>
</tr>
</tbody>
</table>
<p>If I know the inputs, I could try to “predict” the output. This would
state that in the real world the outputs (y) are a function of the
inputs (x). In mathematical terms:</p>
<p><span class="math inline">\(y = f(x)\)</span></p>
<p>For example, if we know multiple features of a house, we could try to
predict whether a person would like it. (based on f.e. Square meters,
number of bedrooms etc.) However, realistically and economically we
cannot always find all the possible features that would predict an
output. It is always affected by some uncertainty. Therefore, y is a
function of x but adding some noise. Which leads to:</p>
<p>Deterministic function: <span class="math inline">\(y = f(x) + E\)</span></p>
<p>E = (error) noise, a random variable which models some unpredictable
events that happens in the real world that we do not have a
corresponding input for to take into account.</p>
<p>We assume that E obeys at least a couple of properties:</p>
<ol style="list-style-type: decimal">
<li>E is not correlated with any of the features</li>
<li>Expected value of the random variable, E[E] = 0</li>
</ol>
<p>Assumption 1 can be F.E. that someone really wants to buy a house
because there is a good place to put a dog bed. This cannot be predicted
based on the other inputs (features) that are in my data set. They
should not be correlated.</p>
<p>Assumption 2 says that the <span class="math inline">\(e\)</span> doesn’t ALWAYS cause either a increase or
a decrease in the output. It has to be truly random.</p>
<hr />
<p>The real world: <span class="math inline">\(y = f(x) + E\)</span>. We want to try to learn more about this
function f.</p>
<p>Estimator = <span class="math inline">\(\hat f\)</span>.</p>
<p>If we do a good job, we are able to find a <span class="math inline">\(\hat f\)</span> that is similar to
the true value of f. If I am able to find a <span class="math inline">\(\hat f\)</span>, I can plug in the
input into the estimator and make a prediction. The estimator is the
thing that I want to use to approximate as best as possible the real
relationship between the inputs and outputs in the real world. In
mathematical terms:</p>
<p><span class="math inline">\(\hat f (x) = \hat y\)</span> = prediction</p>
<p>If the model is <strong>accurate</strong> the prediction is <strong>accurate</strong> =</p>
<p><span class="math inline">\(\hat f\)</span> is similar to <span class="math inline">\(f\)</span> and therefore <span class="math inline">\(\hat y\)</span> is similar to <span class="math inline">\(y\)</span> and
therefore We have accurate predictions.</p>
<p><em>What is key for the data scientist is: <strong>Out-Of-Sample Accuracy.</strong></em></p>
<p>This means that your model is accurate with your sample but also with
out-of-sample data.</p>
<p>How can I measure how accurate <span class="math inline">\(\hat y\)</span> is compared to <span class="math inline">\(y\)</span>? We look at
the error.</p>
<p><strong>Squared error:</strong> Most classical error measure = <span class="math inline">\((y-\hat y)^2\)</span></p>
<p>Multiple reasons on why squared errors are used:</p>
<p>- Taking square means I forget about the sign of the error (negative vs
positive)<br />
- Taking square penalizes more ‘extreme’ errors</p>
<p><img src="images/paste-B4EC7C48.png" /></p>
<p>Alternative way of valuing the error is the <strong>absolute error:</strong>
<span class="math inline">\(y-\hat y\)</span></p>
<div id="data-visualized" class="section level4" number="7.1.1.1">
<h4><span class="header-section-number">7.1.1.1</span> Data Visualized</h4>
<p>Typically we will call our data: x &amp; y</p>
<p>One data point looks like:</p>
<p><span class="math inline">\((x1, x2, …., xp, y)\)</span></p>
<p>Here X1 can be independent variable 1 for example square meters. X2 can
be number of rooms and Xp the year it is build. Y is the price of the
house.</p>
<p><img src="images/paste-0140ACD4.png" width="535" /></p>
</div>
</div>
<div id="finding-the-expected-value-of-the-error" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Finding the expected value of the error</h3>
<p><strong>Random variable:</strong> is described informally as a variable whose values
depend on outcomes of a random phenomenon.</p>
<p>The error is a random variable. Therefore, y is also a random variable
because some of its expression is: <span class="math inline">\(f(x) + ϵ = y\)</span>.</p>
<p><span class="math inline">\(Eϵ[y-\hat y]^2\)</span> = expected value of the squared error</p>
<p>Because we know that the formula for y is = <span class="math inline">\(f(x) + ϵ = y\)</span>, we can
re-write this expression as:</p>
<p><span class="math inline">\(Eϵ[(f(x)+ ϵ-\hat y]^2\)</span></p>
<p>We continue to solve the equation. We can re-write <span class="math inline">\(\hat y\)</span> as
<span class="math inline">\(\hat f(x)\)</span>:</p>
<p><span class="math inline">\(Eϵ[(f(x)+ ϵ-\hat f(x)]^2\)</span></p>
<p>We rearrange these terms:</p>
<p><span class="math inline">\(Eϵ[(f(x)-\hat f(x)+ ϵ]^2\)</span></p>
<p>For ease of notation, <span class="math inline">\(f(x)-\hat f(x)\)</span> becomes alpha</p>
<p><span class="math inline">\(Eϵ[\alpha+ ϵ]^2\)</span></p>
<p>We expand:</p>
<p><span class="math inline">\(Eϵ[\alpha^2 + 2\alphaϵ + ϵ^2]\)</span></p>
<p>Make use of it being linear:</p>
<p><span class="math inline">\(Eϵ[\alpha^2] + 2Eϵ[\alphaϵ] + Eϵ[ϵ^2]\)</span></p>
<p>Now we can see that alpha does not have the random element ϵ making it
not a random variable and is deterministic term (constant). As it is
constant and without error, it is already the expected value. We
re-write again:</p>
<p><span class="math inline">\(\alpha^2 + 2Eϵ[\alphaϵ] + Eϵ[ϵ^2]\)</span></p>
<p>As previously explained in the theory, the expect value of the noise
should be 0. This is the assumption made.</p>
<p><span class="math inline">\(\alpha^2 + 0 + Eϵ[ϵ^2]\)</span></p>
<p>The variance of a random variable is, for example variable z =</p>
<p><span class="math inline">\(Var[z] = E[z^2] - (E[z])^2\)</span></p>
<p>If we apply this definition to the above ϵ:</p>
<p><span class="math inline">\(Var[ϵ] = E[ϵ^2] - (E[ϵ])^2\)</span></p>
<p>As we said before, the expected value of ϵ is 0 and therefore the
variance is:</p>
<p><span class="math inline">\(Var[ϵ] = E[ϵ^2] - 0 = E[ϵ^2]\)</span></p>
<p>To combine this with the previous equation:</p>
<p><span class="math inline">\(\alpha^2 + Eϵ[ϵ^2] = [f(x) - \hat f(x)]^2 + Var[ϵ]\)</span></p>
<p>This can be separated in two parts:</p>
<table style="width:86%;">
<colgroup>
<col width="38%" />
<col width="47%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span class="math inline">\([f(x) - \hat f(x)]^2\)</span></td>
<td><span class="math inline">\(Var[ϵ]\)</span></td>
</tr>
<tr class="even">
<td><p>Reducible error:</p>
<p>Real relation - estimator</p></td>
<td><p>Irreducible error</p>
<p>Intrinsic property of the error</p></td>
</tr>
</tbody>
</table>
<p>If the model is really good, the estimator is similar to the real
relation and I can “reduce” the error. If the model is extremely
precise, the estimator can even be exactly the real relation. It
therefore depends on the accuracy of the estimator.</p>
<p><span class="math inline">\(\hat f = f\)</span></p>
<p>However, even when this happens, I still cannot affect the “irreducible”
error because it is noise from the real world. It is intrinsic property
/ characteristics of the data, not the estimator.</p>
<p>To conclude, we can only affect the reducible error.</p>
<hr />
<p>Data set = <span class="math inline">\((x1, y1)….,(xn, yn)\)</span></p>
<p>Data point i = <span class="math inline">\(Xi ϵR^p\)</span></p>
<p>The estimator is a function that takes a p dimensional and produces a
real values output.</p>
<p><span class="math inline">\(\hat f:R^p –&gt; R\)</span></p>
<p><span class="math inline">\(\hat y = \hat f (x)\)</span>= prediction or estimate</p>
<p><span class="math inline">\(\hat f\)</span> = estimator</p>
<p>If I have a concrete set of observations, I can estimate the expected
value. For example, I can take the average height of a class to estimate
the expected value of the height of the class.</p>
<p>Mean squared error (MSE): The empirical average of the expected value of
the error term. In mathematical terms:</p>
<p><span class="math inline">\(MSE(\hat f) = \frac{1}{n} \sum_{i=1}^{n}(y_i-\hat y_i)^2\)</span></p>
<p>Considering that <span class="math inline">\(\hat y_i\)</span> is nothing else than the prediction for the
i input = <span class="math inline">\(\hat y_i = \hat f(x_i)\)</span>. Therefore, we can transform again:</p>
<p><span class="math inline">\(MSE(\hat f) = \frac{1}{n} \sum_{i=1}^{n}(y_i-\hat f(x_i))^2\)</span></p>
<p>I can apply <span class="math inline">\(\hat f\)</span> to one row, calculate the p features and look at
the real label, to compute the MSE.</p>
<p><img src="images/paste-DDB3C592.png" width="353" /></p>
<p>Mean absolute error (MAE): Hereby the only difference is that it is not
squared.</p>
<p><span class="math inline">\(MAE(\hat f) = \frac{1}{n} \sum_{i=1}^{n}[y_i-\hat f(x_i)]\)</span></p>
<hr />
</div>
<div id="loss-function" class="section level3" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> Loss function</h3>
<p>We can use a loss function which takes as input two numbers: the real
and the predicted value and gives as output another real number. This is
the formula:</p>
<p><span class="math inline">\(L(y, \hat y): R^2 = R\)</span></p>
<table>
<thead>
<tr class="header">
<th>Squared error</th>
<th>Absolute error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(L(y, \hat y) = (y-\hat y)^2\)</span></td>
<td><span class="math inline">\(L(y, \hat y) = (y-\hat y)\)</span></td>
</tr>
</tbody>
</table>
<p><br />
<em>I want the loss function to obey two properties:</em></p>
<ol style="list-style-type: decimal">
<li><p>If I make a correct prediction <span class="math inline">\((\hat y = y)\)</span>, then I have 0 loss
<span class="math inline">\(L(y, \hat y) = 0\)</span> if <span class="math inline">\((\hat y = y)\)</span>.</p></li>
<li><p>For most loss function, I want <span class="math inline">\(L(y, \hat y)\)</span> to be large than the<br />
“wronger” my prediction $$\hat y$ is. The loss function should
not become smaller when the prediction becomes “wronger.” Wronger =
the more different my prediction is than the true number.</p></li>
</ol>
<p>Loss function should be small when my prediction is close to the true
value and it should be large when it is not.</p>
<p>Estimating the error on existing data on which I know the label:</p>
<p><span class="math inline">\(Error(\hat f) = \frac{1}{n} \sum_{i=1}^{n}L(y_i-\hat f(x_i))\)</span></p>
<p>Now I am calculating how accurate my model is based on my data set.
However, we want our model to work well on new previously unseen data
that is out of my data set / sample. In other words: <strong>Out of sample
accuracy.</strong></p>
<p>We therefore, separate our data <strong>randomly</strong> in two parts: the training
set and the test set.</p>
<p><img src="images/paste-ADE4509B.png" width="365" /></p>
<p><strong>Training set:</strong> Data we show our model to have it learn a good
estimator. <span class="math inline">\(\hat f \approx f\)</span>. The training set will be used to derive
to a estimator.</p>
<p><strong>Test set:</strong> Data which we hide from our model. After the model has
been trained, we will simulate it to the test data to evaluate the
model’s performance. The test set will be sued to estimate the error fo
the <span class="math inline">\(\hat f\)</span>.</p>
<p>The training set is called: N = <span class="math inline">\((x_1,y_1)....,(x_n,y_n)\)</span></p>
<p>The test set is called: M = <span class="math inline">\((x_1,y_1)....,(x_m,y_m)\)</span></p>
<p>Therefore, to calculate the estimate of the error of the model:</p>
<p><span class="math inline">\(Err(\hat f) = \frac{1}{n-m} \sum_{i=m+1}^{n}L(y_i-\hat f(x_i))\)</span></p>
<p><br />
To train a model = to find good values for its parameters. First I have
to fix the shape of the model.</p>
<ul>
<li><p><strong>Linear:</strong> <span class="math inline">\(\hat f(x_1-,x_p) = \beta_0+\beta_1,.....+\beta_p X_p\)</span><br />
Beta’s are the linear coefficients and the X1, Xp are the variables.
The <span class="math inline">\(\beta\)</span> ’s are parameters. I can train a model to find a good
estimator by finding good parameters</p></li>
<li><p><strong>Quadratic:</strong>
<span class="math inline">\(\hat f(x_1-,x_p) = \beta_0+\beta_1,.....+\beta_p X_p + \beta_1X_1^2+....\beta_1pX_1p + etc.\)</span></p></li>
</ul>
<p>I do not know what model is the good model. So I train each model and
then I pick the model that has the lowest error.</p>
<p><img src="images/paste-90F835B4.png" /></p>
<p><span class="math inline">\(x\)</span> = an input (p)</p>
<p><span class="math inline">\(\beta\)</span> = a vector of parameters (k)</p>
<p><span class="math inline">\(\beta^*\)</span> = optimal solution of the betas</p>
<p>This is a optimization problem where I try to minimize the empirical
error of the model on the training set. Once we solve the following
model, I find the optimal values for the <span class="math inline">\(\beta\)</span>’s and this will find me
the estimator. Once I have my estimator, I can take the test data and
estimate an error for the model.</p>
<p><strong>Training error
=</strong><span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n}L(y_i-\hat f(\beta_ix_i))\)</span></p>
<p><strong>Test error =</strong>
<span class="math inline">\(Err(\hat f) = \frac{1}{n-m} \sum_{i=m+1}^{n}L(y_i-\hat f(\beta^*_i,x_i))\)</span></p>
<hr />
</div>
</div>
<div id="bias-variance-trade-off" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Bias-variance trade off</h2>
<p><br />
Train/test split = Random variable</p>
<p>Therefore, if I do this twice, I will most likely get different results.
As we now have a different training set, I will find a different optimal
value for <span class="math inline">\(B*\)</span> and therefore the estimator. Subsequently, the estimate
of the error will be different also.</p>
<p>There is a second source of randomness.</p>
<p>Bias-variance trade-off =</p>
<p><span class="math inline">\(E_{Traintestsplit} [(y-\hat y)^2] = Var[\hat y] + (Bias[\hat y])^2 + Var [ϵ]\)</span></p>
<p>How much does the estimator (random variable) defer from the real values</p>
<p><span class="math inline">\(Bias[\hat y] = E[\hat y]-f(x)\)</span> =<span class="math inline">\(Bias^2[\hat y] = (E[\hat y] -f(x))^2\)</span></p>
<p>Recalling:</p>
<p>Variance = <span class="math inline">\(Var[Z] = E[Z^2] - (E[Z])^2\)</span></p>
<p>Rewrite <span class="math inline">\(E[(Z - E[Z])^2\)</span></p>
<p><span class="math inline">\(\mu = E[Z]\)</span></p>
<p><span class="math inline">\(E[(Z-\mu)^2]\)</span></p>
<p>The expected value of a random variable is a constant. Therefore, I can
transform:</p>
<p><span class="math inline">\(E[E[Z]] = E[Z]\)</span></p>
<p>Training test split = the expected value in the following scenario.</p>
<p><span class="math inline">\(E[(y-\hat y)^2] = E[(y-f(x) + f(x) - \hat y)^2]\)</span></p>
<p>Next we can solve this equation:</p>
<p><span class="math inline">\(E[(y-f(x))^2] + 2E[(y-f(x))(f(x)-\hat y)] + E[(f(x)-\hat y)^2]\)</span></p>
<p>Definition of <span class="math inline">\(y = f(x)+ ϵ\)</span></p>
<p><span class="math inline">\(E[ϵ^2] + 2E[yf(x)-(f(x))^2 - y\hat y + \hat yf(x)] + E[(f(x)- \hat y )^2]\)</span></p>
<p>We know that <span class="math inline">\(E[ϵ^2]\)</span> is <span class="math inline">\(var[ϵ]\)</span></p>
<p><img src="images/paste-7FBD2164.png" width="387" /></p>
<p>We want the error of the model to be as low as possible. We cannot
change the noise. Therefore, we want the variance and the trade off to
be as low as possible. The best we can do is that they are both 0.</p>
<p>If you reduce the variance, naturally there will be at least some biased
introduced and vice versa.</p>
<p><img src="images/paste-607116A0.png" width="449" /></p>
<p>The variance of <span class="math inline">\(\hat y\)</span> = How much would the prediction <span class="math inline">\(\hat y\)</span> vary
when we change the training set.</p>
<p>My objective is that the predictor is similar to the real function =
<span class="math inline">\(\hat f \approx f\)</span>. If I have a predictor that varies a lot based on the
training data, it cannot really be similar to the real function.
Naturally, I want the variance of <span class="math inline">\(\hat y\)</span> to be lower.</p>
<p><strong>Model with high variance</strong> = Overfitted model (too complex). A small
change in the training set –&gt; large change in the predictions. This
has a low bias.</p>
<p>If my model learns the noise of the training set, it can make perfect
predictions. However, when you apply the model to a different data set,
it will give bad predictions. Having too many parameters allows the
model to learn the noise.</p>
<p>If a model is very complicated, it is more likely to be overfitted (high
variance, low bias).</p>
<p><strong>Model with high bias</strong> = Underfitted model (too simple). Large error
even in the training set. This typically has a low variance. It is
stable but it will give bad predictions and not accurate.</p>
<p>We can visualize this by plotting a linear regression model. We have
made a small change in the training set (one point has moved) and there
has been a small variance in the regression line.</p>
<p><img src="images/paste-B7BAF89D.png" /></p>
<p><br />
So we can conclude that there is a low variance in the model.</p>
<p><br />
Now we will look at a polynomial model where there is 0 bias. Therefore,
the model must intercept perfectly all the points in the training set.</p>
<p><img src="images/paste-E57B9766.png" /></p>
<p>If I want to intercept 4 points in <span class="math inline">\(R^2\)</span>, what is the smallest degree of
a polynomial that 1 need? –&gt; N-1</p>
<p>The green model has a high variance, but the bias - 0. This is a
overfitted model.</p>
<hr />
<div id="training-fitting-a-model" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Training (fitting) a model</h3>
<p><strong>Training a model:</strong> Finding the parameters (of a parametric model)
which minimize the loss function over the training set.</p>
<p>Training set has N points –&gt; <span class="math inline">\((X_1,Y_1),....,(X_n,Y_n)\)</span>.</p>
<p><em>Minimize our parameters:</em></p>
<p><span class="math inline">\(\beta :=(\beta_1....,\beta_k)\)</span> = The K parameters of my model.</p>
<p>I want to minimize the training error:
<span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n}L(y_i-\hat f(\beta_ix_i))\)</span></p>
<p>k = p+1. These are all the parameters plus the intercept in the example
of a regression model.</p>
<p>Renamed function of betas: <span class="math inline">\(g(\beta)\)</span></p>
<p>Not all functions are born equal. There are some functions that are
easier to deal with. Fe. if they are continuous. In the case if I am in
luck there is a good chance that I can find the minimize. If these
conditions don’t hold it will be very difficult. There is a chance that
a algorithm finds not necessarily the <strong>global minimum</strong> but it does
find the <strong>local minimum.</strong> This can be visualized below:</p>
<p><img src="images/paste-600DC796.png" /></p>
<p><strong>A convex function:</strong> a continuous <strong>function</strong> whose value at the
midpoint of every interval in its domain does not exceed the arithmetic
mean of its values at the ends of the interval.mo</p>
<p>Hereby, the global minimum is automatically also the local minimum as
there is only one.</p>
<p><img src="images/paste-AAF7E2B1.png" width="240" /></p>
<p><strong>Convex vs concave:</strong></p>
<p><img src="images/paste-85CC3A24.png" /></p>
<p>If I want to find a minimum of a function, I need to find a point where
the first derivative vanishes. Multiple things could happen:</p>
<ul>
<li><p>You find a local min (might be global)</p></li>
<li><p>You find a local max (might be global)</p></li>
<li><p>You find a saddle point</p></li>
</ul>
</div>
</div>
<div id="gradient-descent" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Gradient descent</h2>
<p>Instead, we present an algorithm that tries to find the local minimum
using the first derivative. It is a multivariate function as:</p>
<p><span class="math inline">\(g:R^k -&gt; R^+_0\)</span> = <span class="math inline">\(\nabla g\)</span></p>
<p><span class="math inline">\(\nabla g(\beta_1,....,\beta_k)\)</span> =
<span class="math inline">\((\frac{\partial g}{\partial\beta_1}(\beta_1,...,\beta_k),....,\frac{\partial g}{\partial\beta_1}(\beta_1,...,\beta_k))\)</span></p>
<p>a vector that has all the partial derivatives at that point.</p>
<p><strong>Gradient =</strong> a measure of how steep a slope is</p>
<p><strong>Derivative =</strong> of a function of a real variable measures the
sensitivity to change of the function value (output value) with respect
to a change in its argument (input value).</p>
<p><strong>Function =</strong> something that will take a input and will produce a given
output.</p>
<p><br />
We want to go against the gradient (-) to find the minimum. We want to
follow the blue steps to arrive at the minimum (pink).</p>
<p><img src="images/paste-962EC0DD.png" /></p>
<p><strong>Newton’s Algorithm / Gradient Descent Algorithm =</strong> only uses one
parameter = alpha (<span class="math inline">\(\alpha\)</span>), can be any positive number.</p>
<ol style="list-style-type: decimal">
<li><p>Fix an arbitrary <span class="math inline">\(\beta_0R_k\)</span> to start from.</p></li>
<li><p>For t=0,….,T: the maximum number of steps that I will do (going
from <span class="math inline">\(\beta_1 - \beta_2\)</span>). The equation is:</p>
<p><span class="math inline">\(\beta^{t+1} = \beta^t-\alpha\nabla g(\beta^t)\)</span><br />
If the <span class="math inline">\(\nabla g(\beta^{t+1})=0\)</span> then break (You have found the
global minimum if the function in convex)</p></li>
<li><p>Return the last <span class="math inline">\(\beta^t\)</span> available.</p></li>
</ol>
<p><span class="math inline">\(\alpha\)</span> <strong>= The step size / learning rate.</strong></p>
<p>If our function looks like below:</p>
<p><img src="images/paste-341F8419.png" width="318" /></p>
<p>We will find a local minimum and will be stuck in the equation as the
gradient is 0.</p>
<p>The above equation considers a fixed parameter <span class="math inline">\(\alpha\)</span>. It is also
possible to consider a <strong>changing parameter =</strong> <span class="math inline">\(\alpha_t\)</span>.</p>
<p>If <span class="math inline">\(\alpha\)</span> grows, then we move more at each iteration. This could mean
that we move faster as there are fewer iterations. Alternatively, we
start jumping all over the space of the parameters without converging or
converging slowly.</p>
<p>Here is an example of the set size (learning rate) being too large and
experiencing <strong>“jumping”</strong>:</p>
<p><img src="images/paste-A4685804.png" width="311" /></p>
<p><em>How to choose</em> <span class="math inline">\(\alpha\)</span><em>?</em> Trying different values and finding the best
solution. “Typically” <span class="math inline">\(\alpha = 10^{-3} = 0.01\)</span>.</p>
<p>Each iteration of the gradient descent algorithm we do:</p>
<p><span class="math inline">\(\beta^{t+1} = \beta^t-\alpha\nabla g(\beta^t)\)</span></p>
<p><span class="math inline">\(\nabla g(\beta^t) = \nabla(\frac{1}{n} \sum_{i=1}^{n}g_i(\beta^t))\)</span></p>
<p>Rewrite:</p>
<p><span class="math inline">\(\nabla g(\beta^t) = \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta^t)\)</span></p>
<p>To compute <span class="math inline">\(\nabla g\)</span> I used N gradients. These are one for each point
in the training set. This must happen at each iteration.</p>
<p>In big data settings, it is not unlikely that we have a training set
that have millions of data points. This would require too many gradients
(too slow).</p>
<div id="sarcastic-gradient-descent" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Sarcastic gradient descent</h3>
<p>In the previous computation we had to computes <strong>n</strong> gradients =<br />
<span class="math inline">\(\nabla g(\beta^t) = \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta^t)\)</span></p>
<p>However, we can replace this with something that only needs to compute 1
gradient, no matter how large the data set is.</p>
<ol style="list-style-type: decimal">
<li><p>Fix an arbitrary <span class="math inline">\(\beta^0 e R^k\)</span> to start from</p></li>
<li><p>For <span class="math inline">\(t=0,....T:\)</span></p>
<ul>
<li><p>Draw <span class="math inline">\(jϵ\)</span> {1,….,m} with uniform random distribution</p></li>
<li><p><span class="math inline">\(\beta^{t+1} = \beta^t - \alpha \nabla g_j(\beta^t)\)</span></p></li>
<li><p>etc. everything else is like in gradient descent</p></li>
</ul></li>
</ol>
<p>The only difference is how we jump from the iterations. Instead of
computing the entire gradient.</p>
<p><strong>Gradient descent</strong> =
<span class="math inline">\(\beta^{t+1}= \beta^t - \alpha * \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta^t)\)</span></p>
<p>vs</p>
<p><strong>Sarcastic gradient descent</strong> =
<span class="math inline">\(\beta^{t+1}= \beta^t - \alpha \nabla g_j(\beta^t)\)</span></p>
<p>Where J is taken uniformly at random = j~<span class="math inline">\(U({1,....,m})\)</span></p>
<p><strong><em>GD vs SGD</em></strong></p>
<p><img src="images/paste-9CE815C2.png" /></p>
<p><span class="math inline">\(\beta=(\beta_0, \beta_1)\)</span> initial <span class="math inline">\(\beta^0=(\beta^0_0, \beta^0_1)\)</span></p>
<p>next <span class="math inline">\(\beta^1=(\beta^1_0, \beta^1_1)\)</span></p>
<p><strong>Here the MSE</strong><span class="math inline">\((\beta^0)\)</span> <strong>&lt; MSE</strong> <span class="math inline">\(\beta^1\)</span></p>
<p>In linear regression the:
<span class="math inline">\(g(\beta) = \frac{1}{n} \sum_{i=1}^{n}y_i-(\beta^0+\beta^1x_i))^2 = MSE(\beta)\)</span></p>
<p>In sarcastic gradient descent:</p>
<p><span class="math inline">\(g_j(\beta) = y_j-(\beta^0+\beta_1x_j))^2 = SE_j(\beta)\)</span></p>
<p>Here the squared error is only regarding the random point j. The
regression line is changing so that the squared error of j becomes
smaller. By doing so over and over and choosing random uniformly j, it
is as if I was optimizing for all the squared errors. This can be proven
by:</p>
<p>Instead of using:</p>
<p><span class="math inline">\(\nabla g(\beta)= \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta)\)</span></p>
<p>We use:</p>
<p><span class="math inline">\(\nabla g_j(\beta)\)</span></p>
<p>Therefore, in expectation of a discrete random variable:</p>
<p><span class="math inline">\(E [\nabla g_j(\beta)] = \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta) = \nabla g(\beta)\)</span></p>
<p>In expectation the gradient computed on that function <span class="math inline">\(g_j\)</span> is equal to
the big gradient (the gradient with respect to all the points).
Subsequently, on average, the squared error of j is equal to the mean
squared error of all the points.</p>
<ul>
<li><p>SGD needs more iterations then GD. However, each iteration is much
quicker. In the end, you can expect that SGD takes less time than
GD.</p></li>
<li><p>Even if you have a convex differential function, you have less
guarantee. GD with any alpha in 0,1 is guaranteed to converge to the
optimum (global minimum). Sarcastic gradient descent you only
guarantee that you will arrive at a ball around the global minimum.
But inside this ball there is no guarantee anymore.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li>GD</li>
<li>SGD</li>
</ol>
<p><img src="images/paste-A761BC35.png" width="356" /></p>
<p>SGD could jump around in the ball and never arrive to the global
minimum. If this happens, you could go back to classic gradient descent
and try to converge.<br />
</p>
<p><strong>Mini-Batch Gradient descent</strong></p>
<p>Takes the average of a subset of n of size k.</p>
<p><img src="images/paste-C860906C.png" /></p>
<p>These points are mostly not taken at random. Takes k points for each
iteration. 1 epoch has passed per iteration.</p>
<hr />
</div>
</div>
<div id="model-selection-1" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Model Selection</h2>
<p>Model selection = choosing the “best” model out of a set of possible
models that we are trying to consider. The “best” is considering the
out-of-sample predictive accuracy = lowest error (loss) on the point NOT
used for training = test set.</p>
<p>While doing predictions, we want to come up with appropriate estimators
(<span class="math inline">\(\hat f\)</span>) which are similar to our real word function (<span class="math inline">\(f\)</span>), that links
our features to our label. This is expressed in, we want that:
<span class="math inline">\(\hat f \approx f\)</span>.</p>
<p>Typically there are many models that can be used. Therefore, we need to
find out which model is the closest to the real value <span class="math inline">\(f\)</span>. Some models
have hyper parameters that we need to choose which would give us even
more different models.</p>
<p>In machine learning, a <strong>hyper parameter</strong> is a parameter whose value is
used to control the learning process. By contrast, the values of other
parameters (typically node weights) are derived via training. These are
either not trainable through gradient descent or it would not be
effective as it would defeat their purpose.</p>
<p>If we include the hyper parameter through gradient descent, it would be
set to 0. Moreover, setting the alpha to anything other than 0, would
give us a worse model on the training set. Perhaps, this would translate
to a better model on the test set. As we care mainly about the
out-of-sample-accuracy, this would be optimal. Therefore, we need a
different / better way on determining alpha which is different than
gradient descent –&gt; Hyper parameter tuning procedure.</p>
<p><img src="images/paste-4DA3F338.png" /></p>
<p>In the models that include hyper parameters, the are a infinite number
of models for each possible value of <span class="math inline">\(\alpha &gt; 0\)</span> . This complicates the
model selection as we have to decide the best value of $\alpha$.</p>
<p>In order to avoid this, we could choose a model that has 0 hyper
parameters and afterwards add a layer of complexity.</p>
<hr />
<p><strong>Hold-Out validation method</strong></p>
<ul>
<li><p>“simple” if no hyper parameters (training + test)</p></li>
<li><p>“nested” if there are hyper parameters (training + validation +
test)</p></li>
</ul>
<p>Average error of the test set = An estimate of the real error which the
model will exhibit on new unseen data. It is an substitute of the
infinitely many data points that my model will classify when I will use
it for real / in production.</p>
<p>We compare this estimate of the error of the test set (<span class="math inline">\(ERR_1\)</span>) with the
multiple models and choose the lowest value by definition.</p>
<p><img src="images/paste-21B7F2B9.png" /></p>
<p>We can additionally do model selection with hyper parameter tuning
recursively.</p>
<p><strong>Grid Search:</strong> specifying a set of parameters which I believe are
reasonable and try all in sequence.</p>
<p>I believe (intuition or proof of concept) any value large than 1 is
unlikely to be a good value for alpha because it would overemphasize the
penalty of the parameter. In other words, it would cause too much bias
for the reduction of the variance.<br />
</p>
<p><img src="images/paste-38135339.png" /></p>
<p><strong>Hyper parameter tuning =</strong> Holdout validations + Grid search</p>
<p><strong>Nested procedure:</strong></p>
<p><img src="images/paste-C053E1A0.png" /></p>
<p><strong>(i)</strong> For each value of hyper parameters in the grid <span class="math inline">\(\alpha\)</span></p>
<ol style="list-style-type: decimal">
<li>Train the model with the <span class="math inline">\(\alpha\)</span> on the training set</li>
<li>Estimate the error on the validation set</li>
<li>I choose the hyper parameter <span class="math inline">\(\alpha\)</span> which gives the lowest error
estimate on the validation set.</li>
</ol>
<p>Therefore, the chosen <span class="math inline">\(\alpha\)</span> is going to be the hyper parameter
configuration that I am going to use. With this value, I will evaluate
the quality model on the test set.</p>
<p>However, a model that is trained by more data typically performs better
than with little data. By splitting again, the training set becomes
smaller leading to a <em>scarcity</em> of data.</p>
<p><strong>(ii)</strong> Before passing to the next phase, with the fixed parameter,
there is an intermediate step. We retrain <span class="math inline">\(\hat f_{\alpha*}\)</span> on the
entire training + validation set.</p>
<p><strong>(iii)</strong> Estimate the <span class="math inline">\(ERR_{\alpha*,1}\)</span> using the test set.</p>
<hr />
<p><strong>Standardization</strong></p>
<ol style="list-style-type: decimal">
<li>We do not want our model to see the test data during training –&gt;
We do not want any information about the test data to be accessible
by the model during training.</li>
<li>Standardize my data set before starting. Still in the data
exploration phase.</li>
</ol>
<p>If we standardize the data in the beginning before splitting the data
into training/test, the mean and scaling will be on the entire data.
Therefore there is some information of the test set that would flow to
the model. = <strong>Information leakage</strong></p>
<p><em>Alternatively:</em></p>
<ol style="list-style-type: decimal">
<li>We first split the data.</li>
<li>We standardize the training set.</li>
<li>We apply the mean standard deviation on the test set</li>
</ol>
<p><img src="images/paste-90252CDE.png" /></p>
<hr />
<p>The “real” error of my estimator: In the limit when I use and infinite
long data set. Considering we do not have this data set, we find the
empirical estimated error of my estimator using the data in the test
set.</p>
<p>Here 1 is the real error and the 2’s are the estimates. The first has
higher variance than the second.</p>
<p><img src="images/paste-CE33D3FC.png" width="357" /></p>
<ol style="list-style-type: decimal">
<li><p>What is the variance of the estimated error <span class="math inline">\(\hat {ERR}\)</span>? A standard
trick to reduce the variance, is to increase the sample size and
take the average. f.e. bootstrap method.</p></li>
<li><p>What is the bias of estimated error <span class="math inline">\(\hat {ERR}\)</span>? We can try a
larger training set.</p>
<p><img src="images/paste-C4165CF2.png" width="270" height="100" /></p></li>
<li><p>Is my <span class="math inline">\(\hat {ERR}\)</span> consistently an <em>overestimation</em>,
<em>underestimation</em> of <span class="math inline">\(ERR\)</span>.</p></li>
</ol>
<p><span class="math inline">\(\hat f\)</span> is training on the training set: just a smaller subset of the
entire data set. We use it to compute the <span class="math inline">\(\hat {ERR}\)</span>(on the test set).
The <span class="math inline">\(\hat f\)</span> trained on the training set is worse than the <span class="math inline">\(\hat f\)</span> on
the entire data-set. The <span class="math inline">\(\hat {ERR}\)</span> obtained using the <span class="math inline">\(\hat f\)</span>
training on the training set is worse than the <span class="math inline">\(ERR\)</span> (the error made by
<span class="math inline">\(\hat f\)</span> trained on the entire data set, in the limit).</p>
<p>When I will use <span class="math inline">\(\hat f\)</span> in production, I will re-train it on the entire
data-set.</p>
<p>Therefore, <span class="math inline">\(\hat {ERR}\)</span> is likely going to be larger than the <span class="math inline">\(ERR\)</span>.
<span class="math inline">\(\hat {ERR}\)</span> will be an overestimation of the <span class="math inline">\(ERR\)</span>. For an error to be
worse, it implies it is larger than the actual error.</p>
<p>Bias is due to the overestimation of the true error.</p>
<div id="reducing-bias" class="section level4" number="7.4.0.1">
<h4><span class="header-section-number">7.4.0.1</span> Reducing bias</h4>
<p><strong>Training set selection probabilities</strong></p>
<p><img src="images/paste-AABFAA7B.png" /></p>
<p><span class="math inline">\(\frac{1}{n} =\)</span> Probability that a point is chosen for the training set
during 1 draw</p>
<p><span class="math inline">\(1-\frac{1}{n} =\)</span> Probability that a point is <strong>NOT</strong> chosen for the
training set during 1 draw</p>
<p><span class="math inline">\((1-\frac{1}{n})^n =\)</span> The probability that a point is <strong>NOT</strong> chosen
during all the n draws</p>
<p>Limitation n -&gt; infinite -&gt;
<span class="math inline">\((1-\frac{1}{n})^n = e^{-1} \approx 0.3678\)</span></p>
<p>Subsequently, 36.78% of the points are never chosen. 100-36.78% = 63.2%
go into the training set. These are the only values that are unique.</p>
<p>The larger the data set, the better the model as the estimate of the
error is less bias. However, the estimate of the error is affected by
the size of the test set. Therefore, we want to balance the
test-training proportions.</p>
<p><em>The trick to reduce the variance is to average observations.</em></p>
<p><strong>Leave-One-Out Cross-validation method (LOOCV):</strong></p>
<p>We leave one out of the training set n times and find an estimator. Then
we average the estimations:</p>
<p><span class="math inline">\(\frac{1}{m} \sum_{i=1}^{m}\hat {ERR}^{(i)}\)</span></p>
<p><strong>Disadvantages LOOCV:</strong></p>
<ul>
<li><p>Crazy amount of computing power. Extremely time consuming. If n is
huge, it will take too much time. In HPT, we train each model n(n-1)
*. This takes even longer. Does not scale with: big data + complex
model</p></li>
<li><p>There is still typically high variance compared with estimates
obtained with other validation methods. This depends on the data &amp;
models used.</p></li>
</ul>
<p><strong>K-Fold Cross Validation</strong></p>
<p>The model will be trained k times. K = between 2 and N. Primarily the
data set is split k times into what is called <strong>“folds”</strong>, that are
roughly the sames size. In each iteration we take a different fold as
the test set and the rest as the training set.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg" /></p>
<p>At every iteration we receive an <span class="math inline">\(\hat {ERR}\)</span> and the final used is the
average of k iterations. These are estimated on the test fold (fold #1)
when $\hat f$ is trained on all other folds (#2…#k). This method
trades off the computing power vs bias.</p>
<ul>
<li><p>If K = small:</p>
<ul>
<li><p>Smaller training set -&gt; more bias</p></li>
<li><p>Fewer iterations -&gt; less computing power</p></li>
</ul></li>
</ul>
<!-- -->
<ul>
<li><p>If K = large:</p>
<ul>
<li><p>Larger training set -&gt; less bias</p></li>
<li><p>More iterations -&gt; more computing power</p></li>
</ul></li>
</ul>
<p>In practice, empirically using k=5 or 10 already has very accurate
results. This is typically used.</p>
<p>If the model has hyper parameters, the k-fold can be applied for the
model selection and the k-fold hyper parameter tuning. Therefore it will
be <span class="math inline">\(k^2\)</span> folds. It might be that this is not computationally feasible.
It can also be that holdout validation is used for the models election
and k-fold cv for hyper parameter tuning.</p>
<p><strong>Comparing methods:</strong></p>
<table>
<thead>
<tr class="header">
<th>Holdout Validation</th>
<th>LOOCV</th>
<th>K-Fold Cross validation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>High bias</td>
<td>Low bias</td>
<td>Depends on K</td>
</tr>
<tr class="even">
<td>Reasonable computation time</td>
<td>Crazy computation time (low)</td>
<td>Depends on K</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="classification-problems" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Classification Problems</h2>
<p>The label is not numeric but it is a member of a discrete set.</p>
<p><em>Examples:</em></p>
<table style="width:75%;">
<colgroup>
<col width="31%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th>Classification</th>
<th>Label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>y {Spam, Not Spam}</td>
<td>Binary Classification</td>
</tr>
<tr class="even">
<td><p>y {0, 1]</p>
<p>Negative vs Positive</p></td>
<td>Binary with one-hot encoding</td>
</tr>
<tr class="odd">
<td>y {Dog, Cat, Rabbit}</td>
<td>Multi-class classification</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th>Real class</th>
<th>-1</th>
<th>+1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Predicted class</strong></td>
<td>-1</td>
<td>True Negative</td>
<td>False Negative</td>
</tr>
<tr class="even">
<td></td>
<td>+1</td>
<td>False Positive</td>
<td>True Positive</td>
</tr>
</tbody>
</table>
<p>The features are: <span class="math inline">\(XϵR^p\)</span> . The feature that is categorical is converted
to numerical values through one-hot-encoding.</p>
<p>We have to define appropriate loss functions. We ask to output the
probability that the observation is either -1 or +1.</p>
<ol style="list-style-type: decimal">
<li>Classifier <span class="math inline">\(\hat f:R^p\)</span> -&gt; {-1, +1}</li>
<li>Classifier <span class="math inline">\(\hat f:R^p\)</span> -&gt; [0,1]. <span class="math inline">\(\hat y = P[y=+1]\)</span></li>
</ol>
<p>At which threshold do we want to consider the observation to be 0 or 1
depends on the confidence of the results. This could be done through:</p>
<ul>
<li><p>If <span class="math inline">\(\hat y &gt; 0.5\)</span> -&gt; 1</p></li>
<li><p>If <span class="math inline">\(\hat y &lt; 0.5\)</span> -&gt; 0</p></li>
</ul>
<p>The threshold depends on the cost of making a mistake in a false
positive vs false negative.</p>
<p><strong>Loss function</strong></p>
<p>In classification problems there are two loss functions:</p>
<ul>
<li><p>Surrogate loss function</p></li>
<li><p>Loss function</p></li>
</ul>
<p>Minimizing the average surrogate loss function will lower the loss
function on the test.</p>
<p><img src="images/paste-32905236.png" /></p>
<p>Binary loss <span class="math inline">\(l(y,\hat y)\)</span> = 1+ if <span class="math inline">\(\hat y \neq y\)</span> &amp; 0 if <span class="math inline">\(\hat y = y\)</span></p>
<p>We want to use the binary loss for selecting the model but not for
training the model.</p>
<div id="evaluating-model-quality" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Evaluating model quality</h3>
<p>To see which measures are commonly used to evaluate the quality of the
model and perform model selection, the table below can be used:</p>
<p><img src="images/paste-D2149627.png" width="584" /></p>
<ul>
<li>Recall = True positive rate (TPR). Probability of prediction.
<span class="math inline">\(\frac {y+and\hat y+}{y+}\)</span></li>
<li>False positive rate. Fall out = Probability of false alarm</li>
<li>Precision = positive predictive value
<span class="math inline">\(\frac {y+and\hat y+}{\hat y+}\)</span></li>
<li>False negative rate (FNR). Miss rate</li>
</ul>
<p>The perfect prediction is recall = 1 &amp; precision = 1. The bad prediction
is recall = 0 &amp; precision = 0.</p>
<p><img src="images/paste-C83C7277.png" width="427" /></p>
<p><img src="images/paste-46CFCBC5.png" /></p>
<p>Accuracy = # times the model is correct / number of predictions</p>
<p><span class="math inline">\(\frac {(correct \hat y)}{predictions}\)</span> or <span class="math inline">\(TP/TN\)</span></p>
<p>We have to be careful with a unbalanced data set. This means that the
amount of 0 are much more than the amounts of 1’s or vice versa. If we
are only concerned about the accuracy, it might be that there is a very
low discriminate power.</p>
<p><em>F.e.</em> if a data set has 99 positives and 1 negative, the model could
adopt always classify as positive and it would be accurate 99% of the
time. What is more important, is to identify correctly that 1
observation that is negative.</p>
<p><span class="math inline">\(\hat f(x) = p\)</span></p>
<p>t = threshold if <span class="math inline">\(p &gt; t\)</span> -&gt; Positive (+1) if <span class="math inline">\(p &lt; t\)</span> -&gt; Positive (+1)</p>
<p>if t=0 -&gt; only prediction positive, where TPR = 1, FPR = 1 if t=1 -&gt;
only prediction negative, where TPR = 0, FPR = 0</p>
<p>TPR = # true positives / # positive obs FPR = # false positives / #
negatives obs</p>
<p>Receiver Operating Characteristics (ROC)</p>
<p><img src="images/paste-46894C12.png" /></p>
<p>A perfect model = green<br />
Random model = orange</p>
<p>The light blue is closer to the perfect model. Therefore, we would
select this model.</p>
<p>AUC = area under the curve</p>
</div>
<div id="multi-class-classification" class="section level3" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> Multi-class classification</h3>
<p>Most models only support binary classification. Some models natively
support multiple classification such as neural networks. However, there
are ways to transforms models to support multi-class classifiers. There
are two ways:</p>
<p><strong>1 vs 1 method:</strong> <span class="math inline">\(y{A,B,C}\)</span></p>
<ul>
<li><span class="math inline">\(\hat f_{A,B} (x)[A,B]\)</span></li>
<li><span class="math inline">\(\hat f_{B,C} (x)[B,C]\)</span></li>
<li><span class="math inline">\(\hat f_{A,C} (x)[A,C]\)</span></li>
</ul>
<p>After training each model, we use an input (x,y) and predict the
classification: - <span class="math inline">\(\hat f_{A,B} (x)= A\)</span> - <span class="math inline">\(\hat f_{B,C} (x)= B\)</span> -
<span class="math inline">\(\hat f_{A,C} (x)= A\)</span></p>
<p>Which ever group is voted most, will be the one classified. In this
case, we have the most A’s.</p>
<p>Advantage of this method is that the binary classifiers can be of any
type. The drawback is that there are k possible classes. If there are
many, classes, this will be a lot of work.</p>
<p><strong>1 vs All (other) method:</strong> <span class="math inline">\(y{A,B,C}\)</span></p>
<ul>
<li><span class="math inline">\(\hat f_A(x)[A, -A]\)</span> -&gt; <span class="math inline">\(P_a\)</span></li>
<li><span class="math inline">\(\hat f_B(x)[B, -B]\)</span> -&gt; <span class="math inline">\(P_b\)</span></li>
<li><span class="math inline">\(\hat f_C(x)[C, -C]\)</span> -&gt; <span class="math inline">\(P_C\)</span></li>
</ul>
<p>Then we choose the highest probability as it has the highest confidence.</p>
<p>The advantages is that it only needs k classifiers. However, there needs
to be models that outputs probabilities. It is more likely in this
approach that the estimators are more precise to the 1-vs-1
classification. As each model here can be trained on the entire data
set.</p>
<p><img src="images/paste-B6B55442.png" /></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basics-python.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="advanced-statistical-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["R-Summaries.pdf", "R-Summaries.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
