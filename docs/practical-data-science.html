<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter - 7 Practical data science | Business Analytics - Cheatsheets &amp; Summary</title>
  <meta name="description" content="This is a summary of r code learned throughout several courses of my master in management." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter - 7 Practical data science | Business Analytics - Cheatsheets &amp; Summary" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a summary of r code learned throughout several courses of my master in management." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter - 7 Practical data science | Business Analytics - Cheatsheets &amp; Summary" />
  
  <meta name="twitter:description" content="This is a summary of r code learned throughout several courses of my master in management." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basics-python.html"/>
<link rel="next" href="advanced-statistical-methods.html"/>
<script src="libs/header-attrs-2.7/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Cheatsheets & Summary</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="basics-r.html"><a href="basics-r.html"><i class="fa fa-check"></i><b>1</b> Basics R</a>
<ul>
<li class="chapter" data-level="1.0.1" data-path="basics-r.html"><a href="basics-r.html#tables-frames-matrices"><i class="fa fa-check"></i><b>1.0.1</b> Tables, frames &amp; Matrices</a></li>
<li class="chapter" data-level="1.1" data-path="basics-r.html"><a href="basics-r.html#data-sets"><i class="fa fa-check"></i><b>1.1</b> Data sets</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="basics-r.html"><a href="basics-r.html#removing-infinite-na-values"><i class="fa fa-check"></i><b>1.1.1</b> Removing infinite + NA values</a></li>
<li class="chapter" data-level="1.1.2" data-path="basics-r.html"><a href="basics-r.html#transforming-variable-types"><i class="fa fa-check"></i><b>1.1.2</b> Transforming variable types</a></li>
<li class="chapter" data-level="1.1.3" data-path="basics-r.html"><a href="basics-r.html#markdown"><i class="fa fa-check"></i><b>1.1.3</b> Markdown</a></li>
<li class="chapter" data-level="1.1.4" data-path="basics-r.html"><a href="basics-r.html#setup-rmarkdown-code-chunks"><i class="fa fa-check"></i><b>1.1.4</b> Setup rmarkdown &amp; code chunks</a></li>
<li class="chapter" data-level="1.1.5" data-path="basics-r.html"><a href="basics-r.html#latex"><i class="fa fa-check"></i><b>1.1.5</b> Latex</a></li>
<li class="chapter" data-level="1.1.6" data-path="basics-r.html"><a href="basics-r.html#miscellaneous"><i class="fa fa-check"></i><b>1.1.6</b> Miscellaneous</a></li>
<li class="chapter" data-level="1.1.7" data-path="basics-r.html"><a href="basics-r.html#subsetting"><i class="fa fa-check"></i><b>1.1.7</b> Subsetting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="charts-templates-r.html"><a href="charts-templates-r.html"><i class="fa fa-check"></i><b>2</b> Charts templates - R</a></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#bayes-theorem"><i class="fa fa-check"></i><b>3.1</b> Bayes Theorem</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#discrete-probablity"><i class="fa fa-check"></i><b>3.2</b> Discrete Probablity</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="probability.html"><a href="probability.html#uniform-discrete-probability-distribution"><i class="fa fa-check"></i><b>3.2.1</b> Uniform discrete probability distribution</a></li>
<li class="chapter" data-level="3.2.2" data-path="probability.html"><a href="probability.html#binomial-distribution"><i class="fa fa-check"></i><b>3.2.2</b> Binomial distribution</a></li>
<li class="chapter" data-level="3.2.3" data-path="probability.html"><a href="probability.html#poisson-distribution"><i class="fa fa-check"></i><b>3.2.3</b> Poisson distribution</a></li>
<li class="chapter" data-level="3.2.4" data-path="probability.html"><a href="probability.html#the-normal-distribution"><i class="fa fa-check"></i><b>3.2.4</b> The normal distribution</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#samples-estimation-confidence-intervals"><i class="fa fa-check"></i><b>3.3</b> Samples, estimation &amp; confidence intervals</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#significance-level"><i class="fa fa-check"></i><b>3.4</b> Significance level</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="probability.html"><a href="probability.html#critical-values"><i class="fa fa-check"></i><b>3.4.1</b> Critical values</a></li>
<li class="chapter" data-level="3.4.2" data-path="probability.html"><a href="probability.html#test-of-equality---two-samples"><i class="fa fa-check"></i><b>3.4.2</b> Test of equality - two samples</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#non-parametric-testing"><i class="fa fa-check"></i><b>3.5</b> Non-Parametric testing</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="probability.html"><a href="probability.html#contengency-table-frequencies"><i class="fa fa-check"></i><b>3.5.1</b> Contengency table / frequencies</a></li>
<li class="chapter" data-level="3.5.2" data-path="probability.html"><a href="probability.html#chi-square"><i class="fa fa-check"></i><b>3.5.2</b> Chi-square</a></li>
<li class="chapter" data-level="3.5.3" data-path="probability.html"><a href="probability.html#goodness-of-fit"><i class="fa fa-check"></i><b>3.5.3</b> Goodness of fit</a></li>
<li class="chapter" data-level="3.5.4" data-path="probability.html"><a href="probability.html#p-value"><i class="fa fa-check"></i><b>3.5.4</b> P-value</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simple-regressions.html"><a href="simple-regressions.html"><i class="fa fa-check"></i><b>4</b> Simple regressions</a>
<ul>
<li class="chapter" data-level="4.1" data-path="simple-regressions.html"><a href="simple-regressions.html#basics-regressions"><i class="fa fa-check"></i><b>4.1</b> Basics regressions</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="simple-regressions.html"><a href="simple-regressions.html#summarizing-regressions"><i class="fa fa-check"></i><b>4.1.1</b> Summarizing regressions:</a></li>
<li class="chapter" data-level="4.1.2" data-path="simple-regressions.html"><a href="simple-regressions.html#dummy-variables-diff-in-means"><i class="fa fa-check"></i><b>4.1.2</b> Dummy variables, diff in means</a></li>
<li class="chapter" data-level="4.1.3" data-path="simple-regressions.html"><a href="simple-regressions.html#regression-dummy"><i class="fa fa-check"></i><b>4.1.3</b> Regression + dummy</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="simple-regressions.html"><a href="simple-regressions.html#prediction"><i class="fa fa-check"></i><b>4.2</b> Prediction</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="simple-regressions.html"><a href="simple-regressions.html#confidence-and-prediction-plotting"><i class="fa fa-check"></i><b>4.2.1</b> Confidence and prediction plotting</a></li>
<li class="chapter" data-level="4.2.2" data-path="simple-regressions.html"><a href="simple-regressions.html#prediction-with-dummy-variables"><i class="fa fa-check"></i><b>4.2.2</b> Prediction with dummy variables</a></li>
<li class="chapter" data-level="4.2.3" data-path="simple-regressions.html"><a href="simple-regressions.html#prediction-intervals-examples"><i class="fa fa-check"></i><b>4.2.3</b> Prediction intervals examples</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="simple-regressions.html"><a href="simple-regressions.html#data-problems"><i class="fa fa-check"></i><b>4.3</b> Data problems</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="simple-regressions.html"><a href="simple-regressions.html#multicollinearity"><i class="fa fa-check"></i><b>4.3.1</b> Multicollinearity</a></li>
<li class="chapter" data-level="4.3.2" data-path="simple-regressions.html"><a href="simple-regressions.html#variance-inflation-factors"><i class="fa fa-check"></i><b>4.3.2</b> Variance inflation factors</a></li>
<li class="chapter" data-level="4.3.3" data-path="simple-regressions.html"><a href="simple-regressions.html#anova"><i class="fa fa-check"></i><b>4.3.3</b> ANOVA</a></li>
<li class="chapter" data-level="4.3.4" data-path="simple-regressions.html"><a href="simple-regressions.html#linearizing-variables"><i class="fa fa-check"></i><b>4.3.4</b> Linearizing variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="structure-equation-models.html"><a href="structure-equation-models.html"><i class="fa fa-check"></i><b>5</b> Structure equation models</a>
<ul>
<li class="chapter" data-level="5.1" data-path="structure-equation-models.html"><a href="structure-equation-models.html#path-analysis-structural-equations"><i class="fa fa-check"></i><b>5.1</b> Path analysis (structural equations)</a></li>
<li class="chapter" data-level="5.2" data-path="structure-equation-models.html"><a href="structure-equation-models.html#coding-the-model"><i class="fa fa-check"></i><b>5.2</b> Coding the model</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="structure-equation-models.html"><a href="structure-equation-models.html#covariance"><i class="fa fa-check"></i><b>5.2.1</b> Covariance</a></li>
<li class="chapter" data-level="5.2.2" data-path="structure-equation-models.html"><a href="structure-equation-models.html#reliability"><i class="fa fa-check"></i><b>5.2.2</b> Reliability</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="structure-equation-models.html"><a href="structure-equation-models.html#factor-model"><i class="fa fa-check"></i><b>5.3</b> Factor model</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="structure-equation-models.html"><a href="structure-equation-models.html#setting-covariance-variances"><i class="fa fa-check"></i><b>5.3.1</b> Setting covariance &amp; variances</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="basics-python.html"><a href="basics-python.html"><i class="fa fa-check"></i><b>6</b> Basics Python</a>
<ul>
<li class="chapter" data-level="6.1" data-path="basics-python.html"><a href="basics-python.html#data-set"><i class="fa fa-check"></i><b>6.1</b> Data set</a></li>
<li class="chapter" data-level="6.2" data-path="basics-python.html"><a href="basics-python.html#matrixes"><i class="fa fa-check"></i><b>6.2</b> Matrixes</a></li>
<li class="chapter" data-level="6.3" data-path="basics-python.html"><a href="basics-python.html#filtering-a-data-set"><i class="fa fa-check"></i><b>6.3</b> Filtering a data set</a></li>
<li class="chapter" data-level="6.4" data-path="basics-python.html"><a href="basics-python.html#data-imputation"><i class="fa fa-check"></i><b>6.4</b> Data imputation</a></li>
<li class="chapter" data-level="6.5" data-path="basics-python.html"><a href="basics-python.html#data-visualization"><i class="fa fa-check"></i><b>6.5</b> Data visualization</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="basics-python.html"><a href="basics-python.html#other-categorical-plots"><i class="fa fa-check"></i><b>6.5.1</b> Other categorical plots</a></li>
<li class="chapter" data-level="6.5.2" data-path="basics-python.html"><a href="basics-python.html#preparing-the-data"><i class="fa fa-check"></i><b>6.5.2</b> Preparing the data</a></li>
<li class="chapter" data-level="6.5.3" data-path="basics-python.html"><a href="basics-python.html#creating-the-models"><i class="fa fa-check"></i><b>6.5.3</b> Creating the models</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="basics-python.html"><a href="basics-python.html#model-selection"><i class="fa fa-check"></i><b>6.6</b> Model selection</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="basics-python.html"><a href="basics-python.html#svc"><i class="fa fa-check"></i><b>6.6.1</b> SVC</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="practical-data-science.html"><a href="practical-data-science.html"><i class="fa fa-check"></i><b>7</b> Practical data science</a>
<ul>
<li class="chapter" data-level="7.1" data-path="practical-data-science.html"><a href="practical-data-science.html#machine-learning"><i class="fa fa-check"></i><b>7.1</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="practical-data-science.html"><a href="practical-data-science.html#theory"><i class="fa fa-check"></i><b>7.1.1</b> Theory</a></li>
<li class="chapter" data-level="7.1.2" data-path="practical-data-science.html"><a href="practical-data-science.html#data-set-1"><i class="fa fa-check"></i><b>7.1.2</b> Data set</a></li>
<li class="chapter" data-level="7.1.3" data-path="practical-data-science.html"><a href="practical-data-science.html#finding-the-expected-value-of-the-error"><i class="fa fa-check"></i><b>7.1.3</b> Finding the expected value of the error</a></li>
<li class="chapter" data-level="7.1.4" data-path="practical-data-science.html"><a href="practical-data-science.html#finding-the-error"><i class="fa fa-check"></i><b>7.1.4</b> Finding the error</a></li>
<li class="chapter" data-level="7.1.5" data-path="practical-data-science.html"><a href="practical-data-science.html#loss-function"><i class="fa fa-check"></i><b>7.1.5</b> Loss function</a></li>
<li class="chapter" data-level="7.1.6" data-path="practical-data-science.html"><a href="practical-data-science.html#training-vs-test-set"><i class="fa fa-check"></i><b>7.1.6</b> Training vs test set</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="practical-data-science.html"><a href="practical-data-science.html#bias-variance-trade-off"><i class="fa fa-check"></i><b>7.2</b> Bias-variance trade off</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="practical-data-science.html"><a href="practical-data-science.html#training-fitting-a-model"><i class="fa fa-check"></i><b>7.2.1</b> Training (fitting) a model</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="practical-data-science.html"><a href="practical-data-science.html#gradient-descent"><i class="fa fa-check"></i><b>7.3</b> Gradient descent</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="practical-data-science.html"><a href="practical-data-science.html#stochastic-gradient-descent"><i class="fa fa-check"></i><b>7.3.1</b> Stochastic gradient descent</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="practical-data-science.html"><a href="practical-data-science.html#model-selection-1"><i class="fa fa-check"></i><b>7.4</b> Model Selection</a></li>
<li class="chapter" data-level="7.5" data-path="practical-data-science.html"><a href="practical-data-science.html#validations-methods"><i class="fa fa-check"></i><b>7.5</b> Validations methods</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="practical-data-science.html"><a href="practical-data-science.html#hold-out-validation-method"><i class="fa fa-check"></i><b>7.5.1</b> <strong>Hold-Out validation method</strong></a></li>
<li class="chapter" data-level="7.5.2" data-path="practical-data-science.html"><a href="practical-data-science.html#standardization"><i class="fa fa-check"></i><b>7.5.2</b> <strong>Standardization</strong></a></li>
<li class="chapter" data-level="7.5.3" data-path="practical-data-science.html"><a href="practical-data-science.html#leave-one-out-cross-validation-method-loocv"><i class="fa fa-check"></i><b>7.5.3</b> <strong>Leave-One-Out Cross-validation method (LOOCV):</strong></a></li>
<li class="chapter" data-level="7.5.4" data-path="practical-data-science.html"><a href="practical-data-science.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>7.5.4</b> <strong>K-Fold Cross Validation</strong></a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="practical-data-science.html"><a href="practical-data-science.html#classification-problems"><i class="fa fa-check"></i><b>7.6</b> Classification Problems</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="practical-data-science.html"><a href="practical-data-science.html#evaluating-model-quality"><i class="fa fa-check"></i><b>7.6.1</b> Evaluating model quality</a></li>
<li class="chapter" data-level="7.6.2" data-path="practical-data-science.html"><a href="practical-data-science.html#receiver-operating-characteristics-roc"><i class="fa fa-check"></i><b>7.6.2</b> Receiver Operating Characteristics (ROC)</a></li>
<li class="chapter" data-level="7.6.3" data-path="practical-data-science.html"><a href="practical-data-science.html#multi-class-classification"><i class="fa fa-check"></i><b>7.6.3</b> Multi-class classification</a></li>
<li class="chapter" data-level="7.6.4" data-path="practical-data-science.html"><a href="practical-data-science.html#maximal-margin-classifier"><i class="fa fa-check"></i><b>7.6.4</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="7.6.5" data-path="practical-data-science.html"><a href="practical-data-science.html#support-vector-classifier"><i class="fa fa-check"></i><b>7.6.5</b> Support vector classifier</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="practical-data-science.html"><a href="practical-data-science.html#regularization"><i class="fa fa-check"></i><b>7.7</b> Regularization</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="practical-data-science.html"><a href="practical-data-science.html#interpretability"><i class="fa fa-check"></i><b>7.7.1</b> Interpretability</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html"><i class="fa fa-check"></i><b>8</b> Advanced Statistical Methods</a>
<ul>
<li class="chapter" data-level="8.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#clustering"><i class="fa fa-check"></i><b>8.1</b> Clustering</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#hierachical-clustering"><i class="fa fa-check"></i><b>8.1.1</b> Hierachical clustering</a></li>
<li class="chapter" data-level="8.1.2" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#non-hierachical-clustering"><i class="fa fa-check"></i><b>8.1.2</b> Non-Hierachical clustering</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#multi-dimensional-scaling"><i class="fa fa-check"></i><b>8.2</b> Multi-Dimensional Scaling</a></li>
<li class="chapter" data-level="8.3" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#principal-component-analysis"><i class="fa fa-check"></i><b>8.3</b> Principal component analysis</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#biplots"><i class="fa fa-check"></i><b>8.3.1</b> Biplots</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#correspondence-analysis"><i class="fa fa-check"></i><b>8.4</b> Correspondence analysis</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#multiple-correspondence-analysis"><i class="fa fa-check"></i><b>8.4.1</b> Multiple Correspondence Analysis</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#multiple-linear-regression-classification-trees"><i class="fa fa-check"></i><b>8.5</b> Multiple linear regression &amp; classification trees</a></li>
<li class="chapter" data-level="8.6" data-path="advanced-statistical-methods.html"><a href="advanced-statistical-methods.html#text-analytics"><i class="fa fa-check"></i><b>8.6</b> Text analytics</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="marketing-analytics.html"><a href="marketing-analytics.html"><i class="fa fa-check"></i><b>9</b> Marketing Analytics</a>
<ul>
<li class="chapter" data-level="9.1" data-path="marketing-analytics.html"><a href="marketing-analytics.html#logistic-regressions"><i class="fa fa-check"></i><b>9.1</b> Logistic regressions</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="marketing-analytics.html"><a href="marketing-analytics.html#sensitivity-vs-specificity"><i class="fa fa-check"></i><b>9.1.1</b> Sensitivity vs Specificity</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="marketing-analytics.html"><a href="marketing-analytics.html#conjoint-analytics"><i class="fa fa-check"></i><b>9.2</b> Conjoint Analytics</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="marketing-analytics.html"><a href="marketing-analytics.html#random-utility-model"><i class="fa fa-check"></i><b>9.2.1</b> Random utility model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Business Analytics - Cheatsheets &amp; Summary</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="practical-data-science" class="section level1" number="7">
<h1><span class="header-section-number">Chapter - 7</span> Practical data science</h1>
<p><em>Class given by: Alberto Santini</em></p>
<div id="machine-learning" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Machine Learning</h2>
<p>There are multiple types of machine learning:</p>
<ul>
<li><p>Supervised</p></li>
<li><p>Unsupervised</p></li>
<li><p>Reinforcement learning</p></li>
</ul>
<p><strong>Reinforcement learning:</strong></p>
<p><strong>Reinforcement learning</strong> (RL) is an area of <strong>machine learning</strong>
concerned with how intelligent agents ought to take actions in an
environment in order to maximize the notion of cumulative reward. An
example of application is by playing chess where through trial and
error, the algorithm was eventually able to beat any player. First they
are taught the simple rules and then asked to train by themselves and
learn from their mistakes. The algorithms are asked to make a move and
either receive:</p>
<ul>
<li><p>A reward or</p></li>
<li><p>A penalty</p></li>
</ul>
<p>As a result, they learn which moves are good and continue to try
something else. However, machine learning still does not understand
casual relationships.</p>
<p><strong>Unsupervised learning:</strong></p>
<p>Unsupervised learning is a type of algorithm that learns patterns from
unlabeled data. The hope is that, through mimicry, the machine is forced
to build a compact internal representation of its world and then
generate imaginative content. While there are no labels available, the
algorithm can still observe patterns and understand that there are
commonalities. Again, it won’t be able to understand causality.</p>
<p>It is possible to combine labeled data, for example from the passed and
look for patterns with the unlabeled data.</p>
<p><img src="images/paste-0F7C76CE.png" width="656" /></p>
<p><strong>Supervised learning</strong></p>
<p><strong>Supervised learning</strong> is an approach to creating <strong>artificial
intelligence</strong> (<strong>AI</strong>), where a computer algorithm is trained on input
data that has been labeled for a particular output. Therefore, it is
extracting patterns from data and making predictions based on passed
behavior.</p>
<p>An example is a picture of an animal and the algorithms predicts which
animal it is. Hereby we use training data to train the algorithm.
However, the data must be labeled meaning we already know the correct
answer. This method does not include trial or error.</p>
<p>For example, first showing examples of cats and then it can make
predictions. Then we show a new picture and it can predict whether it is
a cat or not a cat. There are also multiple types of models than can be
applied for supervised learning such as:</p>
<ul>
<li><p>Regression tasks: label is a continuous number. Hereby what we want
to predict is continuous, not necessarily the data given to predict.
F.E. House prices</p></li>
<li><p>Classification tasks: Label is one of discrete set of possible
values. F.E. Is it a dog or a cat. Or it is a score from 1 to 5,
integer.</p></li>
</ul>
<div id="theory" class="section level3" number="7.1.1">
<h3><span class="header-section-number">7.1.1</span> Theory</h3>
<p>Throughout this chapter, only supervised learning is explored in the two
methods: regression and classification.</p>
<table style="width:97%;">
<colgroup>
<col width="22%" />
<col width="75%" />
</colgroup>
<thead>
<tr class="header">
<th>Symbol</th>
<th>Explanation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>y</td>
<td><p>The real value. Generic output. The label. (ML) The
thing I want to predict.</p>
<p>Dependent variable (statistics).</p></td>
</tr>
<tr class="even">
<td><strong>ŷ</strong></td>
<td>Prediction</td>
</tr>
<tr class="odd">
<td><strong>y-ŷ</strong></td>
<td>Absolute error</td>
</tr>
<tr class="even">
<td><strong>( y-ŷ)^2</strong></td>
<td>Squared error</td>
</tr>
<tr class="odd">
<td><strong>x</strong></td>
<td><p>Generic input / Features. The things I use to
predict y.</p>
<p>The independent variable (statistics).</p></td>
</tr>
<tr class="even">
<td><strong>p</strong></td>
<td><p>Number of features (machine learning).</p>
<p>Number of independent variables I have
(statistics).</p></td>
</tr>
<tr class="odd">
<td><strong>n</strong></td>
<td>Size of the data set</td>
</tr>
</tbody>
</table>
<p>If I know the inputs, I could try to “predict” the output. This would
state that in the real world, the outputs (y) are a function of the
inputs (x). In mathematical terms:</p>
<p><span class="math inline">\(y = f(x)\)</span></p>
<p>For example, if we know multiple features of a house, we could try to
predict whether a person would like it. (based on f.e. square meters,
number of bedrooms etc.) However, realistically and economically we
cannot always find all the possible features that would predict an
output. It is always affected by some uncertainty. Therefore, y is a
function of x but adding some noise. Which leads to:</p>
<p>Deterministic function: <span class="math inline">\(y = f(x) + ϵ\)</span></p>
<p><strong>ϵ</strong> = (error) noise –&gt; a random variable which models some
unpredictable events that happens in the real world, that we do not have
a corresponding input for to take into account.</p>
<p>We assume that ϵ obeys at least a couple of properties:</p>
<ol style="list-style-type: decimal">
<li>ϵ is not correlated with any of the features</li>
<li>Expected value of the random variable, ϵ[ϵ] = 0</li>
</ol>
<p>Assumption 1 can be F.E. that someone really wants to buy a house
because there is a good place to put a dog bed. This cannot be predicted
based on the other inputs (features) that are in my data set. They
should not be correlated.</p>
<p>Assumption 2 says that the <span class="math inline">\(e\)</span> doesn’t ALWAYS cause either a increase or
a decrease in the output. It has to be truly random.</p>
<hr />
<p>In the real word we have the following: <span class="math inline">\(y = f(x) + E\)</span>. Next we want to
try to learn more about this function f. In order to be able to do so,
we have to find an estimator. The estimator is the thing that I want to
use to approximate as best as possible the real relationship between the
inputs and outputs in the real world.</p>
<p>Estimator = <span class="math inline">\(\hat f\)</span></p>
<p>If we do a good job, we are able to find a <span class="math inline">\(\hat f\)</span> that is similar to
the true value of f. If I am able to find a <span class="math inline">\(\hat f\)</span>, I can plug in the
input into the estimator and make a prediction. In mathematical terms:</p>
<p><span class="math inline">\(\hat f (x) = \hat y\)</span> = prediction</p>
<p>If the model is <strong>accurate</strong> the prediction is <strong>accurate</strong> =</p>
<p><span class="math inline">\(\hat f\)</span> is similar to <span class="math inline">\(f\)</span> and therefore <span class="math inline">\(\hat y\)</span> is similar to <span class="math inline">\(y\)</span> –&gt;
We have accurate predictions.</p>
<blockquote>
<p>What is key for the data scientist -&gt; <strong>Out-Of-Sample Accuracy.</strong></p>
</blockquote>
<p>This means that your model is accurate with your sample but also with
out-of-sample data. How can I measure how accurate <span class="math inline">\(\hat y\)</span> is compared
to <span class="math inline">\(y\)</span>? We can have a look at the error.</p>
<p><strong>Squared error:</strong> Most classical error measure = <span class="math inline">\((y-\hat y)^2\)</span></p>
<p>Multiple reasons on why squared errors are used:</p>
<p>- Taking square means I forget about the sign of the error (negative vs
positive)<br />
- Taking square penalizes more ‘extreme’ errors</p>
<p><img src="images/paste-B4EC7C48.png" /></p>
<p>Alternative way of valuing the error is the <strong>absolute error:</strong>
<span class="math inline">\(y-\hat y\)</span></p>
</div>
<div id="data-set-1" class="section level3" number="7.1.2">
<h3><span class="header-section-number">7.1.2</span> Data set</h3>
<p>Typically we will call our data: x &amp; y. One data point looks like:</p>
<p><span class="math inline">\((x1, x2, …., xp, y)\)</span></p>
<p>Taken the example of predicting house prices, the X1 can be independent
variable 1 for example square meters. X2 can be number of rooms and XP
the year it is build. Y is the price of the house.</p>
<p><img src="images/paste-0140ACD4.png" width="535" /></p>
<hr />
</div>
<div id="finding-the-expected-value-of-the-error" class="section level3" number="7.1.3">
<h3><span class="header-section-number">7.1.3</span> Finding the expected value of the error</h3>
<p>A <strong>random variable</strong> is a <strong>variable</strong> whose value is unknown or a
function that assigns values to each of an experiment’s outcomes. A
<strong>random variable</strong> can be either discrete (having specific values) or
continuous (any value in a continuous range). It is described informally
as a variable whose values depend on outcomes of a random phenomenon.</p>
<p>The error is a random variable. Therefore, y is also a random variable
because some of its expression is: <span class="math inline">\(f(x) + ϵ = y\)</span>.</p>
<p><span class="math inline">\(Eϵ[y-\hat y]^2\)</span> = expected value of the squared error</p>
<p>Because we know that the formula for y is = <span class="math inline">\(f(x) + ϵ = y\)</span>, we can
re-write this expression as:</p>
<p><span class="math inline">\(Eϵ[(f(x)+ ϵ-\hat y]^2\)</span></p>
<p>We continue to solve the equation. We can re-write <span class="math inline">\(\hat y\)</span> as
<span class="math inline">\(\hat f(x)\)</span>:</p>
<p><span class="math inline">\(Eϵ[(f(x)+ ϵ-\hat f(x)]^2\)</span></p>
<p>We rearrange these terms:</p>
<p><span class="math inline">\(Eϵ[(f(x)-\hat f(x)+ ϵ]^2\)</span></p>
<p>For ease of notation, <span class="math inline">\(f(x)-\hat f(x)\)</span> becomes alpha</p>
<p><span class="math inline">\(Eϵ[\alpha+ ϵ]^2\)</span></p>
<p>We expand:</p>
<p><span class="math inline">\(Eϵ[\alpha^2 + 2\alphaϵ + ϵ^2]\)</span></p>
<p>Make use of it being linear:</p>
<p><span class="math inline">\(Eϵ[\alpha^2] + 2Eϵ[\alphaϵ] + Eϵ[ϵ^2]\)</span></p>
<p>Now we can see that alpha does not have the random element ϵ making it
not a random variable and is <strong>deterministic term</strong> (constant). As it is
constant and without error, it is already the expected value. We
re-write again:</p>
<p><span class="math inline">\(\alpha^2 + 2Eϵ[\alphaϵ] + Eϵ[ϵ^2]\)</span></p>
<p>As previously explained in the theory, the expect value of the noise
should be 0. This is the assumption made.</p>
<p><span class="math inline">\(\alpha^2 + 0 + Eϵ[ϵ^2]\)</span></p>
<p>The variance of a random variable is, for example variable z =</p>
<p><span class="math inline">\(Var[z] = E[z^2] - (E[z])^2\)</span></p>
<p>If we apply this definition to the above ϵ:</p>
<p><span class="math inline">\(Var[ϵ] = E[ϵ^2] - (E[ϵ])^2\)</span></p>
<p>As we said before, the expected value of ϵ is 0 and therefore the
variance is:</p>
<p><span class="math inline">\(Var[ϵ] = E[ϵ^2] - 0 = E[ϵ^2]\)</span></p>
<p>To combine this with the previous equation:</p>
<p><span class="math inline">\(\alpha^2 + Eϵ[ϵ^2] = [f(x) - \hat f(x)]^2 + Var[ϵ]\)</span></p>
<p>This final expression can be separated in two parts:</p>
<table style="width:86%;">
<colgroup>
<col width="38%" />
<col width="47%" />
</colgroup>
<tbody>
<tr class="odd">
<td><span class="math inline">\([f(x) - \hat f(x)]^2\)</span></td>
<td><span class="math inline">\(Var[ϵ]\)</span></td>
</tr>
<tr class="even">
<td><p><strong>Reducible error:</strong></p>
<p>Real relation - estimator</p></td>
<td><p><strong>Irreducible error</strong></p>
<p>Intrinsic property of the error</p></td>
</tr>
</tbody>
</table>
<p>If the model is really good, the estimator is similar to the real
relation and I can “reduce” the error. If the model is extremely
precise, the estimator can even be exactly the real relation. It
therefore depends on the accuracy of the estimator.</p>
<p><span class="math inline">\(\hat f = f\)</span></p>
<p>However, even when this happens, I still cannot affect the “irreducible”
error because it is noise from the real world. It is intrinsic property
/ characteristics of the data, not the estimator.</p>
<blockquote>
<p>To reiterate, we can only affect the reducible error.</p>
</blockquote>
</div>
<div id="finding-the-error" class="section level3" number="7.1.4">
<h3><span class="header-section-number">7.1.4</span> Finding the error</h3>
<p>Data point i = <span class="math inline">\(Xi ϵR^p\)</span></p>
<p>The estimator is a function that takes a p dimensional and produces a
real values output.</p>
<p><span class="math inline">\(\hat f:R^p –&gt; R\)</span></p>
<p>If I have a concrete set of observations, I can estimate the expected
value. For example, I can take the average height of a class to estimate
the expected value of the height of the class.</p>
<p><strong>Mean squared error (MSE):</strong> The empirical average of the expected
value of the error term. The average squared difference between the
estimated values and the actual value. In mathematical terms:</p>
<p><span class="math inline">\(MSE(\hat f) = \frac{1}{n} \sum_{i=1}^{n}(y_i-\hat y_i)^2\)</span></p>
<p>Considering that <span class="math inline">\(\hat y_i\)</span> is nothing else than the prediction for the
i input = <span class="math inline">\(\hat y_i = \hat f(x_i)\)</span>, it can be transformed again:</p>
<p><span class="math inline">\(MSE(\hat f) = \frac{1}{n} \sum_{i=1}^{n}(y_i-\hat f(x_i))^2\)</span></p>
<p>I can apply <span class="math inline">\(\hat f\)</span> to one row, calculate the p features and look at
the real label, to compute the MSE.</p>
<p><img src="images/paste-DDB3C592.png" width="626" /></p>
<p><strong>Mean absolute error (MAE):</strong> Here the only difference is that it is
not squared.</p>
<p><span class="math inline">\(MAE(\hat f) = \frac{1}{n} \sum_{i=1}^{n}[y_i-\hat f(x_i)]\)</span></p>
<hr />
</div>
<div id="loss-function" class="section level3" number="7.1.5">
<h3><span class="header-section-number">7.1.5</span> Loss function</h3>
<p>We can use a loss function which takes as input two numbers: the real
and the predicted value and gives as an output another real number. This
is the formula:</p>
<p><span class="math inline">\(L(y, \hat y): R^2 = R\)</span></p>
<table>
<thead>
<tr class="header">
<th>Squared error</th>
<th>Absolute error</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><span class="math inline">\(L(y, \hat y) = (y-\hat y)^2\)</span></td>
<td><span class="math inline">\(L(y, \hat y) = (y-\hat y)\)</span></td>
</tr>
</tbody>
</table>
<p><br />
<em>I want the loss function to obey two properties:</em></p>
<ol style="list-style-type: decimal">
<li><p>If I make a correct prediction <span class="math inline">\((\hat y = y)\)</span>, then I have 0 loss
<span class="math inline">\(L(y, \hat y) = 0\)</span> if <span class="math inline">\((\hat y = y)\)</span>.</p></li>
<li><p>For most loss function, I want <span class="math inline">\(L(y, \hat y)\)</span> to be large than the
“wronger” my prediction . The loss function should not become
smaller when the prediction becomes “wronger.” Wronger = the more
different my prediction is than the true number.</p></li>
</ol>
<p>The loss function should be small when my prediction is close to the
true value and it should be large when it is not. Estimating the error
on existing data on which I know the label:</p>
<p><span class="math inline">\(Error(\hat f) = \frac{1}{n} \sum_{i=1}^{n}L(y_i-\hat f(x_i))\)</span></p>
</div>
<div id="training-vs-test-set" class="section level3" number="7.1.6">
<h3><span class="header-section-number">7.1.6</span> Training vs test set</h3>
<p>Now it is being calculated how accurate the model is based on the
available data set. However, we want the model to work well on new
previously unseen data that is out of the data set / sample. In other
words: <strong>Out of sample accuracy.</strong></p>
<p>Therefore, the data is separated <strong>randomly</strong> in two parts: the training
set and the test set.</p>
<p><img src="images/paste-ADE4509B.png" width="686" /></p>
<blockquote>
<p><strong>Training set:</strong> A subset to train a model. Data we show our model to
have it learn a good estimator. <span class="math inline">\(\hat f \approx f\)</span>. The training set
will be used to derive to a estimator.</p>
<p><strong>Test set:</strong> A subset to test the trained model​. Data which we hide
from our model. After the model has been trained, we will simulate it
to the test data to evaluate the model’s performance. The test set
will be used to estimate the error of the <span class="math inline">\(\hat f\)</span>.</p>
</blockquote>
<p>The training set is called: N = <span class="math inline">\((x_1,y_1)....,(x_n,y_n)\)</span></p>
<p>The test set is called: M = <span class="math inline">\((x_1,y_1)....,(x_m,y_m)\)</span></p>
<p>Therefore, to calculate the estimate of the error of the model:</p>
<p><span class="math inline">\(Err(\hat f) = \frac{1}{n-m} \sum_{i=m+1}^{n}L(y_i-\hat f(x_i))\)</span></p>
<p><br />
To train a model means to find good values for its parameters. First the
shape of the model has to be fixed. As previously stated, there are
several options. The below offers some of the options for regression
problems:</p>
<ul>
<li><p><strong>Linear:</strong> <span class="math inline">\(\hat f(x_1-,x_p) = \beta_0+\beta_1,.....+\beta_p X_p\)</span><br />
Beta’s are the linear coefficients and the X1, XP are the variables.
The <span class="math inline">\(\beta\)</span> ’s are parameters. I can train a model to find a good
estimator by finding good parameters.</p></li>
<li><p><strong>Quadratic:</strong>
<span class="math inline">\(\hat f(x_1-,x_p) = \beta_0+\beta_1,.....+\beta_p X_p + \beta_1X_1^2+....\beta_1pX_1p + etc.\)</span></p></li>
</ul>
<p>Prior to analysis, it isn’t always clear what model will perform better.
Subsequently, the data is trained on multiple models and the final
selection is based on the lowest error.</p>
<p><img src="images/paste-90F835B4.png" /></p>
<p><span class="math inline">\(x\)</span> = an input (p)</p>
<p><span class="math inline">\(\beta\)</span> = a vector of parameters (k)</p>
<p><span class="math inline">\(\beta^*\)</span> = optimal solution of the betas</p>
<p>This is a optimization problem the goal is to minimize the empirical
error of the model on the training set. Once the model is fitted to the
data, the optimal values for the <span class="math inline">\(\beta\)</span>’s are found which will
therefore be the estimator. Once the estimator is found, it is applied
to the test data and an error for the model estimated. In mathematical
terms:</p>
<p><strong>Training error
=</strong><span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n}L(y_i-\hat f(\beta_ix_i))\)</span></p>
<p><strong>Test error =</strong>
<span class="math inline">\(Err(\hat f) = \frac{1}{n-m} \sum_{i=m+1}^{n}L(y_i-\hat f(\beta^*_i,x_i))\)</span></p>
<hr />
</div>
</div>
<div id="bias-variance-trade-off" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Bias-variance trade off</h2>
<p>Splitting the test and training set is performed in a random manner.
Thus, if the split is made twice, it will most likely get different
results. As there are now different training sets with different data
points, an different optimal value for <span class="math inline">\(B*\)</span> is found leading to
additionally a different estimator and estimate of the error.
Nevertheless, there is a second source of randomness.</p>
<p>Bias-variance trade-off =</p>
<p><span class="math inline">\(E_{Traintestsplit} [(y-\hat y)^2] = Var[\hat y] + (Bias[\hat y])^2 + Var [ϵ]\)</span></p>
<p>How much does the estimator (random variable) defer from the real values</p>
<p><span class="math inline">\(Bias[\hat y] = E[\hat y]-f(x)\)</span> =<span class="math inline">\(Bias^2[\hat y] = (E[\hat y] -f(x))^2\)</span></p>
<p>Recalling:</p>
<p>Variance = <span class="math inline">\(Var[Z] = E[Z^2] - (E[Z])^2\)</span></p>
<p>Rewrite <span class="math inline">\(E[(Z - E[Z])^2\)</span></p>
<p><span class="math inline">\(\mu = E[Z]\)</span></p>
<p><span class="math inline">\(E[(Z-\mu)^2]\)</span></p>
<p>The expected value of a random variable is a constant. Therefore, I can
transform:</p>
<p><span class="math inline">\(E[E[Z]] = E[Z]\)</span></p>
<p>Training test split = the expected value in the following scenario.</p>
<p><span class="math inline">\(E[(y-\hat y)^2] = E[(y-f(x) + f(x) - \hat y)^2]\)</span></p>
<p>Next we can solve this equation:</p>
<p><span class="math inline">\(E[(y-f(x))^2] + 2E[(y-f(x))(f(x)-\hat y)] + E[(f(x)-\hat y)^2]\)</span></p>
<p>Definition of <span class="math inline">\(y = f(x)+ ϵ\)</span></p>
<p><span class="math inline">\(E[ϵ^2] + 2E[yf(x)-(f(x))^2 - y\hat y + \hat yf(x)] + E[(f(x)- \hat y )^2]\)</span></p>
<p>We know that <span class="math inline">\(E[ϵ^2]\)</span> is <span class="math inline">\(var[ϵ]\)</span></p>
<p><img src="images/paste-7FBD2164.png" width="684" /></p>
<p>The aim is to make the error of the model as low as possible. Naturally,
the noise cannot be affected. Therefore, the variance and the trade off
needs to be as low as possible. The best scenario is that they are both
0.</p>
<p>Unfortunately if the variance is reduced, naturally there will be at
least some biased introduced and vice verse.</p>
<p><img src="images/paste-607116A0.png" width="684" /></p>
<p>The variance of <span class="math inline">\(\hat y\)</span> = How much the prediction <span class="math inline">\(\hat y\)</span> varies when
the training set is changed.</p>
<p>Remember that the ultimate goal is that the predictor is similar to the
real function = <span class="math inline">\(\hat f \approx f\)</span>. If the predictor varies a lot based
on the training data, it cannot really be similar to the real function.
Hence, I want the variance of <span class="math inline">\(\hat y\)</span> to be low.</p>
<blockquote>
<p><strong>Model with high variance</strong> = Overfitted model (too complex). A small
change in the training set leads to a large change in the predictions.
This has a low bias.</p>
</blockquote>
<p>If the model learns the noise of the training set, it can make perfect
predictions. Although in this instance, when the model is applied to a
different data set, it will give bad predictions. Having too many
parameters allows the model to learn the noise. If a model is very
complicated, it is more likely to be overfitted (high variance, low
bias).</p>
<blockquote>
<p><strong>Model with high bias</strong> = Underfitted model (too simple). Large error
even in the training set. This typically has a low variance. It is
stable but it will give bad predictions and wont be accurate.</p>
</blockquote>
<p>It can be visualized by plotting a linear regression model. We have made
a small change in the training set (one point has moved) and there has
been a small variance in the regression line.</p>
<p><img src="images/paste-B7BAF89D.png" /></p>
<p><br />
So we can conclude that there is a low variance in this model. Now we
will look at a polynomial model where there is 0 bias. Therefore, the
model must intercept perfectly all the points in the training set.</p>
<p><img src="images/paste-E57B9766.png" /></p>
<p>If I want to intercept 4 points in <span class="math inline">\(R^2\)</span>, what is the smallest degree of
a polynomial that 1s need? –&gt; N-1</p>
<p>The green model has a high variance, but the bias = 0. This is a
overfitted model.</p>
<hr />
<div id="training-fitting-a-model" class="section level3" number="7.2.1">
<h3><span class="header-section-number">7.2.1</span> Training (fitting) a model</h3>
<p><strong>Training a model:</strong> Finding the parameters (of a parametric model)
which minimize the loss function over the training set. Training a model
simply means learning (determining) good values for all the weights and
the bias from labeled examples.</p>
<p>Training set has N points –&gt; <span class="math inline">\((X_1,Y_1),....,(X_n,Y_n)\)</span>.</p>
<p><em>Minimize our parameters:</em></p>
<p><span class="math inline">\(\beta :=(\beta_1....,\beta_k)\)</span> = The K parameters of my model.</p>
<p>The goal is to minimize the error -&gt;
<span class="math inline">\(\frac{1}{n} \sum_{i=1}^{n}L(y_i-\hat f(\beta_ix_i))\)</span></p>
<p>k = p+1. These are all the parameters plus the intercept in the example
of a regression model.</p>
<p>Renamed function of betas: <span class="math inline">\(g(\beta)\)</span></p>
<p>Not all functions are born equal. There are some functions that are
easier to deal with. F.E. if they are continuous. In the case if I am in
luck there is a good chance that I can find the minimum. If these
conditions don’t hold, it will be very difficult. There is a chance that
a algorithm finds not necessarily the global minimum but it does find
the local minimum. This can be visualized below:</p>
<p><img src="images/paste-600DC796.png" width="700" /></p>
<blockquote>
<p><strong>A convex function:</strong> a continuous function whose value at the
midpoint of every interval in its domain does not exceed the
arithmetic mean of its values at the ends of the interval. Hereby, the
global minimum is automatically also the local minimum as there is
only one.</p>
</blockquote>
<p><img src="images/paste-AAF7E2B1.png" width="418" /></p>
<p><strong>Convex vs concave:</strong></p>
<p><img src="images/paste-85CC3A24.png" /></p>
<p>Whilst trying to find a minimum for a function, a point must be found
where the first derivative vanishes. Multiple things could happen:</p>
<ul>
<li><p>Finding a local min (might be global)</p></li>
<li><p>Finding a local max (might be global)</p></li>
<li><p>You find a saddle point</p></li>
</ul>
<hr />
</div>
</div>
<div id="gradient-descent" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Gradient descent</h2>
<p>Instead, we present an algorithm that tries to find the local minimum
using the first derivative. A vector that has all the partial
derivatives at that point. It is a multivariate function as:</p>
<p><span class="math inline">\(g:R^k -&gt; R^+_0\)</span> = <span class="math inline">\(\nabla g\)</span></p>
<p><span class="math inline">\(\nabla g(\beta_1,....,\beta_k)\)</span> =
<span class="math inline">\((\frac{\partial g}{\partial\beta_1}(\beta_1,...,\beta_k),....,\frac{\partial g}{\partial\beta_1}(\beta_1,...,\beta_k))\)</span></p>
<p><strong>Gradient =</strong> a measure of how steep a slope is</p>
<p><strong>Derivative =</strong> a function of a real variable measures the sensitivity
to change of the function value (output value) with respect to a change
in its argument (input value).</p>
<p><strong>Function =</strong> something that will take a input and will produce a given
output.</p>
<p><br />
We want to go against the gradient (-) to find the minimum by following
the blue steps to arrive at the minimum (pink).</p>
<p><img src="images/paste-962EC0DD.png" /></p>
<p><strong>Newton’s Algorithm / Gradient Descent Algorithm =</strong> Gradient descent
is a first-order iterative optimization algorithm for finding a local
minimum of a differentiable function. The idea is to take repeated steps
in the opposite direction of the gradient (or approximate gradient) of
the function at the current point, because this is the direction of
steepest descent. Only uses one parameter -&gt; alpha (<span class="math inline">\(\alpha\)</span>), can be
any positive number. Below are the steps to find the solution:</p>
<p><span class="math inline">\(\alpha\)</span> <strong>= The step size / learning rate.</strong></p>
<ol style="list-style-type: decimal">
<li><p>Fix an arbitrary <span class="math inline">\(\beta_0R_k\)</span> to start from.</p></li>
<li><p>For t=0,….,T: the maximum number of steps that I will do (going
from <span class="math inline">\(\beta_1 - \beta_2\)</span>). The equation is:</p>
<p><span class="math inline">\(\beta^{t+1} = \beta^t-\alpha\nabla g(\beta^t)\)</span><br />
If the <span class="math inline">\(\nabla g(\beta^{t+1})=0\)</span> then a break. The global minimum
was found if the function is convex.</p></li>
<li><p>Return the last <span class="math inline">\(\beta^t\)</span> available.</p></li>
</ol>
<p>If our function looks like below:</p>
<p><img src="images/paste-341F8419.png" width="554" /></p>
<p>We will find a local minimum and will be stuck in the equation as the
gradient is 0.</p>
<p>The above equation considers a fixed parameter <span class="math inline">\(\alpha\)</span>. It is also
possible to consider a <strong>changing parameter =</strong> <span class="math inline">\(\alpha_t\)</span>.</p>
<p>If <span class="math inline">\(\alpha\)</span> grows, then we move more at each iteration. This could mean
that we move faster as there are fewer iterations. Alternatively, we
start jumping all over the space of the parameters without converging or
converging slowly.</p>
<p>Here is an example of the set size (learning rate) being too large and
experiencing <strong>“jumping”</strong>:</p>
<p><img src="images/paste-A4685804.png" width="311" /></p>
<p><em>How to choose</em> <span class="math inline">\(\alpha\)</span><em>?</em> Trying different values and finding the best
solution. “Typically” <span class="math inline">\(\alpha = 10^{-3} = 0.01\)</span>.</p>
<p>At each iteration of the gradient descent algorithm we do:</p>
<p><span class="math inline">\(\beta^{t+1} = \beta^t-\alpha\nabla g(\beta^t)\)</span></p>
<p><span class="math inline">\(\nabla g(\beta^t) = \nabla(\frac{1}{n} \sum_{i=1}^{n}g_i(\beta^t))\)</span></p>
<p>Rewrite:</p>
<p><span class="math inline">\(\nabla g(\beta^t) = \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta^t)\)</span></p>
<p>To compute <span class="math inline">\(\nabla g\)</span> there occur N gradients. These are one for each
point in the training set. This must happen at each iteration. In big
data settings, it is not unlikely that we have a training set that has
millions of data points. This would require too many gradients (too
slow).</p>
<div id="stochastic-gradient-descent" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Stochastic gradient descent</h3>
<p>In the previous computation we had to compute <strong>n</strong> gradients =<br />
<span class="math inline">\(\nabla g(\beta^t) = \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta^t)\)</span></p>
<p>However, we can replace this with something that only needs to compute 1
gradient, no matter how large the data set is.</p>
<ol style="list-style-type: decimal">
<li><p>Fix an arbitrary <span class="math inline">\(\beta^0 e R^k\)</span> to start from</p></li>
<li><p>For <span class="math inline">\(t=0,....T:\)</span></p>
<ul>
<li><p>Draw <span class="math inline">\(jϵ\)</span> {1,….,m} with uniform random distribution</p></li>
<li><p><span class="math inline">\(\beta^{t+1} = \beta^t - \alpha \nabla g_j(\beta^t)\)</span></p></li>
<li><p>etc. everything else is like in gradient descent</p></li>
</ul></li>
</ol>
<p>The only difference is how we jump from the iterations. Instead of
computing the entire gradient.</p>
<p><strong>Gradient descent</strong> =
<span class="math inline">\(\beta^{t+1}= \beta^t - \alpha * \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta^t)\)</span></p>
<p>vs</p>
<p><strong>Stochastic gradient descent</strong> =
<span class="math inline">\(\beta^{t+1}= \beta^t - \alpha \nabla g_j(\beta^t)\)</span></p>
<p>Where J is taken uniformly at random = j~<span class="math inline">\(U({1,....,m})\)</span></p>
<p><strong><em>GD vs SGD</em></strong></p>
<p><img src="images/paste-9CE815C2.png" /></p>
<p><span class="math inline">\(\beta=(\beta_0, \beta_1)\)</span> initial <span class="math inline">\(\beta^0=(\beta^0_0, \beta^0_1)\)</span></p>
<p>next <span class="math inline">\(\beta^1=(\beta^1_0, \beta^1_1)\)</span></p>
<p><strong>Here the MSE</strong><span class="math inline">\((\beta^0)\)</span> <strong>&lt; MSE</strong> <span class="math inline">\(\beta^1\)</span></p>
<p>In linear regression the:
<span class="math inline">\(g(\beta) = \frac{1}{n} \sum_{i=1}^{n}y_i-(\beta^0+\beta^1x_i))^2 = MSE(\beta)\)</span></p>
<p>In stochastic gradient descent:</p>
<p><span class="math inline">\(g_j(\beta) = y_j-(\beta^0+\beta_1x_j))^2 = SE_j(\beta)\)</span></p>
<p>Here the squared error is only regarding the random point j. The
regression line is changing so that the squared error of j becomes
smaller. By doing so over and over and choosing random uniformly j, it
is as if I was optimizing for all the squared errors. This can be proven
by:</p>
<p>Instead of using:</p>
<p><span class="math inline">\(\nabla g(\beta)= \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta)\)</span></p>
<p>We use:</p>
<p><span class="math inline">\(\nabla g_j(\beta)\)</span></p>
<p>Therefore, in expectation of a discrete random variable:</p>
<p><span class="math inline">\(E [\nabla g_j(\beta)] = \frac{1}{n} \sum_{i=1}^{n}\nabla g_i(\beta) = \nabla g(\beta)\)</span></p>
<p>In expectation the gradient computed on that function <span class="math inline">\(g_j\)</span> is equal to
the big gradient (the gradient with respect to all the points).
Subsequently, on average, the squared error of j is equal to the mean
squared error of all the points.</p>
<ul>
<li><p>SGD needs more iterations then GD. However, each iteration is much
quicker. In the end, you can expect that SGD takes less time than
GD.</p></li>
<li><p>Even if you have a convex differential function, you have less
guarantee. GD with any alpha in 0,1 is guaranteed to converge to the
optimum (global minimum). Stochastic gradient descent you only
guarantee that you will arrive at a ball around the global minimum.
But inside this ball there is no guarantee anymore.</p></li>
</ul>
<ol style="list-style-type: decimal">
<li>GD</li>
<li>SGD</li>
</ol>
<p><img src="images/paste-A761BC35.png" width="356" /></p>
<p>SGD could jump around in the ball and never arrive to the global
minimum. If this happens, you could go back to classic gradient descent
and try to converge.<br />
</p>
<p><strong>Mini-Batch Gradient descent</strong></p>
<p>Takes the average of a subset of n of size k.</p>
<p><img src="images/paste-C860906C.png" /></p>
<p>These points are mostly not taken at random. Takes k points for each
iteration. 1 epoch has passed per iteration.</p>
<hr />
</div>
</div>
<div id="model-selection-1" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Model Selection</h2>
<p>Model selection = choosing the “best” model out of a set of possible
models that we are trying to consider. The “best” is considering the
out-of-sample predictive accuracy = lowest error (loss) on the point NOT
used for training = test set.</p>
<p>While doing predictions, we want to come up with appropriate estimators
(<span class="math inline">\(\hat f\)</span>) which are similar to our real word function (<span class="math inline">\(f\)</span>), that links
our features to our label. Again it is repeated = <span class="math inline">\(\hat f \approx f\)</span>.</p>
<p>Typically there are many models that can be used. Therefore, we need to
find out which model is the closest to the real value <span class="math inline">\(f\)</span>. Some models
have hyper parameters that we need to choose which would give us even
more different models.</p>
<p>In machine learning, a <strong>hyper parameter</strong> is a parameter whose value is
used to control the learning process. By contrast, the values of other
parameters (typically node weights) are derived theough training. These
are either not trainable through gradient descent or it would not be
effective as it would defeat their purpose.</p>
<p>If we include the hyper parameter through gradient descent, it would be
set to 0. Moreover, setting the alpha to anything other than 0, would
give us a worse model on the training set. Perhaps, this would translate
to a better model on the test set. As we care mainly about the
out-of-sample-accuracy, this would be optimal. Therefore, we need a
different / better way on determining alpha which is different than
gradient descent –&gt; Hyper parameter tuning procedure.</p>
<p><img src="images/paste-4DA3F338.png" /></p>
<p>In the models that include hyper parameters, the are a infinite number
of models for each possible value of <span class="math inline">\(\alpha &gt; 0\)</span> . This complicates the
model selection as we have to decide the best value of <span class="math inline">\(\alpha\)</span> .</p>
<p>In order to avoid this, we could choose a model that has 0 hyper
parameters and afterwards add a layer of complexity.</p>
<hr />
</div>
<div id="validations-methods" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Validations methods</h2>
<div id="hold-out-validation-method" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> <strong>Hold-Out validation method</strong></h3>
<ul>
<li><p>“Simple” if no hyper parameters (training + test)</p></li>
<li><p>“Nested” if there are hyper parameters (training + validation +
test)</p></li>
</ul>
<p>Average error of the test set = An estimate of the real error which the
model will exhibit on new unseen data. It is an substitute of the
infinitely many data points that my model will classify when I will use
it for real / in production. We compare this estimate of the error of
the test set (<span class="math inline">\(ERR_1\)</span>) with the multiple models and choose the lowest
value by definition.</p>
<p><img src="images/paste-21B7F2B9.png" /></p>
<p>We can additionally do model selection with hyper parameter tuning
recursively.</p>
<div id="grid-search" class="section level4" number="7.5.1.1">
<h4><span class="header-section-number">7.5.1.1</span> <strong>Grid Search:</strong></h4>
<p>The traditional way of performing hyperparameter optimization has been
grid search (Parameter sweep), which is simply an exhaustive searching
through a manually specified subset of the hyperparameter space for a
learning algorithm. The first step is specifying a set of parameters
which I believe are reasonable and try all in sequence.</p>
<p>I believe (intuition or proof of concept) any value large than 1 is
unlikely to be a good value for alpha because it would overemphasize the
penalty of the parameter. In other words, it would cause too much bias
for the reduction of the variance.<br />
</p>
<p><img src="images/paste-38135339.png" /></p>
<p><strong>Hyper parameter tuning =</strong> Hyperparameter tuning is choosing a set of
optimal hyperparameters for a learning algorithm. A hyperparameter is a
model argument whose value is set before the learning process begins.
This entails holdout validations + Grid search.</p>
<p><strong>Nested procedure:</strong></p>
<p><img src="images/paste-C053E1A0.png" /></p>
<p><strong>(i)</strong> For each value of hyper parameters in the grid <span class="math inline">\(\alpha\)</span></p>
<ol style="list-style-type: decimal">
<li>Train the model with the <span class="math inline">\(\alpha\)</span> on the training set</li>
<li>Estimate the error on the validation set</li>
<li>Choose the hyper parameter <span class="math inline">\(\alpha\)</span> which gives the lowest error
estimate on the validation set</li>
</ol>
<p>Therefore, the chosen <span class="math inline">\(\alpha\)</span> is going to be the hyper parameter
configuration that I am going to use. With this value, I will evaluate
the quality model on the test set. However, a model that is trained by
more data typically performs better than with little data. By splitting
again, the training set becomes smaller leading to a <strong><em>scarcity</em></strong>of
data.</p>
<p><strong>(ii)</strong> Before passing to the next phase, with the fixed parameter,
there is an intermediate step. We retrain <span class="math inline">\(\hat f_{\alpha*}\)</span> on the
entire training + validation set.</p>
<p><strong>(iii)</strong> Estimate the <span class="math inline">\(ERR_{\alpha*,1}\)</span> using the test set.</p>
<hr />
</div>
</div>
<div id="standardization" class="section level3" number="7.5.2">
<h3><span class="header-section-number">7.5.2</span> <strong>Standardization</strong></h3>
<ol style="list-style-type: decimal">
<li>We do not want our model to see the test data during training as we
do not want any information about the test data to be accessible by
the model during training.</li>
<li>Standardize my data set before starting. Still in the data
exploration phase.</li>
</ol>
<p>If we standardize the data in the beginning before splitting the data
into training/test, the mean and scaling will be on the entire data.
Therefore there is some information of the test set that would flow to
the model –&gt; <strong>Information leakage</strong></p>
<p><em>Alternatively:</em></p>
<ol style="list-style-type: decimal">
<li>We first split the data.</li>
<li>We standardize the training set.</li>
<li>We apply the mean standard deviation on the test set</li>
</ol>
<p><img src="images/paste-90252CDE.png" /></p>
<hr />
<p>The “real” error of my estimator: In the limit when I use an infinite
long data set. Considering we do not have this data set, we find the
empirical estimated error of my estimator using the data in the test
set.</p>
<p>Here 1 is the real error and the 2’s are the estimates. The first has
higher variance than the second.</p>
<p><img src="images/paste-CE33D3FC.png" width="406" /></p>
<ol style="list-style-type: decimal">
<li><p>What is the variance of the estimated error <span class="math inline">\(\hat {ERR}\)</span>? A standard
trick to reduce the variance, is to increase the sample size and
take the average. f.e. bootstrap method.</p></li>
<li><p>What is the bias of estimated error <span class="math inline">\(\hat {ERR}\)</span>? We can try a
larger training set.</p>
<p><img src="images/paste-C4165CF2.png" width="384" height="125" /></p></li>
<li><p>Is my <span class="math inline">\(\hat {ERR}\)</span> consistently an <em>overestimation</em>,
<em>underestimation</em> of <span class="math inline">\(ERR\)</span>.</p></li>
</ol>
<p><span class="math inline">\(\hat f\)</span> is training on the training set: just a smaller subset of the
entire data set. We use it to compute the <span class="math inline">\(\hat {ERR}\)</span>(on the test set).
The <span class="math inline">\(\hat f\)</span> trained on the training set is worse than the <span class="math inline">\(\hat f\)</span> on
the entire data-set. The <span class="math inline">\(\hat {ERR}\)</span> obtained using the <span class="math inline">\(\hat f\)</span>
training on the training set is worse than the <span class="math inline">\(ERR\)</span> (the error made by
<span class="math inline">\(\hat f\)</span> trained on the entire data set, in the limit). When I will use
<span class="math inline">\(\hat f\)</span> in production, I will re-train it on the entire data-set.</p>
<p>Therefore, <span class="math inline">\(\hat {ERR}\)</span> is likely going to be larger than the <span class="math inline">\(ERR\)</span>.
<span class="math inline">\(\hat {ERR}\)</span> will be an overestimation of the <span class="math inline">\(ERR\)</span>. For an error to be
worse, it implies it is larger than the actual error. Bias is due to the
overestimation of the true error.</p>
<div id="reducing-bias" class="section level4" number="7.5.2.1">
<h4><span class="header-section-number">7.5.2.1</span> Reducing bias</h4>
<p><strong>Training set selection probabilities</strong></p>
<p><img src="images/paste-AABFAA7B.png" /></p>
<p><span class="math inline">\(\frac{1}{n} =\)</span> Probability that a point is chosen for the training set
during 1 draw</p>
<p><span class="math inline">\(1-\frac{1}{n} =\)</span> Probability that a point is <strong>NOT</strong> chosen for the
training set during 1 draw</p>
<p><span class="math inline">\((1-\frac{1}{n})^n =\)</span> The probability that a point is <strong>NOT</strong> chosen
during all the n draws</p>
<p>Limitation n -&gt; infinite -&gt;
<span class="math inline">\((1-\frac{1}{n})^n = e^{-1} \approx 0.3678\)</span></p>
<p>Subsequently, 36.78% of the points are never chosen. 100-36.78% = 63.2%
go into the training set. These are the only values that are unique.</p>
<p>The larger the data set, the better the model as the estimate of the
error is less bias. However, the estimate of the error is affected by
the size of the test set. Therefore, we want to balance the
test-training proportions.</p>
<blockquote>
<p><em>The trick to reduce the variance is to average observations.</em></p>
</blockquote>
<p>There are several methods to reduce the variance such applying different
validation methods. Below K-fold and leave on out methods are further
explained.</p>
<hr />
</div>
</div>
<div id="leave-one-out-cross-validation-method-loocv" class="section level3" number="7.5.3">
<h3><span class="header-section-number">7.5.3</span> <strong>Leave-One-Out Cross-validation method (LOOCV):</strong></h3>
<p>We leave one out of the training set n times and find an estimator. Then
we average the estimations:</p>
<p><span class="math inline">\(\frac{1}{m} \sum_{i=1}^{m}\hat {ERR}^{(i)}\)</span></p>
<p><strong>Disadvantages LOOCV:</strong></p>
<ul>
<li><p>Crazy amount of computing power. Extremely time consuming. If n is
huge, it will take too much time. In HPT, we train each model n(n-1)
*. This takes even longer. Does not scale with: big data + complex
model</p></li>
<li><p>There is still typically high variance compared with estimates
obtained with other validation methods. This depends on the data &amp;
models used.</p></li>
</ul>
<hr />
</div>
<div id="k-fold-cross-validation" class="section level3" number="7.5.4">
<h3><span class="header-section-number">7.5.4</span> <strong>K-Fold Cross Validation</strong></h3>
<p>The model will be trained k times. K = between 2 and N. Primarily the
data set is split k times into what is called <strong>“folds”</strong>, that are
roughly the sames size. In each iteration we take a different fold as
the test set and the rest as the training set.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/b/b5/K-fold_cross_validation_EN.svg" width="733" /></p>
<p>At every iteration we receive an <span class="math inline">\(\hat {ERR}\)</span> and the final used is the
average of k iterations. These are estimated on the test fold (fold #1)
when <span class="math inline">\(\hat f\)</span> is trained on all other folds (#2…#k). This method
trades off the computing power vs bias.</p>
<ul>
<li><p>If K = small:</p>
<ul>
<li><p>Smaller training set -&gt; more bias</p></li>
<li><p>Fewer iterations -&gt; less computing power</p></li>
</ul></li>
<li><p>If K = large:</p>
<ul>
<li><p>Larger training set -&gt; less bias</p></li>
<li><p>More iterations -&gt; more computing power</p></li>
</ul></li>
</ul>
<p>In practice, empirically using k=5 or 10 already has very accurate
results. This is typically used.</p>
<p>If the model has hyper parameters, the k-fold can be applied for the
model selection and the k-fold hyper parameter tuning. Therefore it will
be <span class="math inline">\(k^2\)</span> folds. It might be that this is not computationally feasible.
It can also be that holdout validation is used for the models selection
and k-fold for hyper parameter tuning.</p>
<p><strong>Comparing methods:</strong></p>
<table>
<thead>
<tr class="header">
<th>Holdout Validation</th>
<th>LOOCV</th>
<th>K-Fold Cross validation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>High bias</td>
<td>Low bias</td>
<td>Depends on K</td>
</tr>
<tr class="even">
<td>Reasonable computation time</td>
<td>Crazy computation time (high)</td>
<td>Depends on K</td>
</tr>
</tbody>
</table>
<hr />
</div>
</div>
<div id="classification-problems" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Classification Problems</h2>
<p>A classification model attempts to draw some conclusion from observed
values. Given one or more inputs a classification model will try to
predict the value of one or more outcomes. Outcomes are labels that can
be applied to a data set. It is applied when the label is not continuous
but it is a member of a discrete set.</p>
<p><em>Examples:</em></p>
<table style="width:75%;">
<colgroup>
<col width="31%" />
<col width="43%" />
</colgroup>
<thead>
<tr class="header">
<th>Classification</th>
<th>Label</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>y {Spam, Not Spam}</td>
<td>Binary Classification</td>
</tr>
<tr class="even">
<td>y {0, 1]</td>
<td><p>Binary with one-hot encoding</p>
<p>Negative vs Positive</p></td>
</tr>
<tr class="odd">
<td>y {Dog, Cat, Rabbit}</td>
<td>Multi-class classification</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr class="header">
<th></th>
<th>Real class</th>
<th>-1</th>
<th>+1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><strong>Predicted class</strong></td>
<td>-1</td>
<td>True Negative</td>
<td>False Negative</td>
</tr>
<tr class="even">
<td></td>
<td>+1</td>
<td>False Positive</td>
<td>True Positive</td>
</tr>
</tbody>
</table>
<p>The features are: <span class="math inline">\(XϵR^p\)</span> . If the feature is categorical, it is
converted to numerical values by one-hot-encoding.</p>
<p>We have to define appropriate loss functions. We ask to output the
probability that the observation is either -1 or +1.</p>
<ol style="list-style-type: decimal">
<li>Classifier <span class="math inline">\(\hat f:R^p\)</span> -&gt; {-1, +1}</li>
<li>Classifier <span class="math inline">\(\hat f:R^p\)</span> -&gt; [0,1]. <span class="math inline">\(\hat y = P[y=+1]\)</span></li>
</ol>
<p>At which threshold do we want to consider the observation to be 0 or 1
depends on the confidence of the results. The most typical manner:</p>
<ul>
<li><p>If <span class="math inline">\(\hat y &gt; 0.5\)</span> -&gt; 1</p></li>
<li><p>If <span class="math inline">\(\hat y &lt; 0.5\)</span> -&gt; 0</p></li>
</ul>
<p>The threshold depends on the cost of making a mistake in a false
positive vs false negative.</p>
<p><strong>Loss function</strong></p>
<p>In classification problems there are two loss functions:</p>
<ul>
<li><p>Surrogate loss function</p></li>
<li><p>Loss function</p></li>
</ul>
<p>Minimizing the average surrogate loss function will lower the loss
function on the test.</p>
<p><img src="images/paste-32905236.png" /></p>
<p>Binary loss <span class="math inline">\(l(y,\hat y)\)</span> = 1+ if <span class="math inline">\(\hat y \neq y\)</span> &amp; 0 if <span class="math inline">\(\hat y = y\)</span></p>
<p>We want to use the binary loss for selecting the model but not for
training the model.</p>
<div id="evaluating-model-quality" class="section level3" number="7.6.1">
<h3><span class="header-section-number">7.6.1</span> Evaluating model quality</h3>
<p>To see which measures are commonly applied to evaluate the quality of
the model and perform model selection, the table below can be used:</p>
<p><img src="images/paste-D2149627.png" width="844" /></p>
<ul>
<li>Recall = True positive rate (TPR). Probability of prediction.
<span class="math inline">\(\frac {y+and\hat y+}{y+}\)</span></li>
<li>False positive rate. Fall out = Probability of false alarm</li>
<li>Precision = positive predictive value
<span class="math inline">\(\frac {y+and\hat y+}{\hat y+}\)</span></li>
<li>False negative rate (FNR). Miss rate</li>
</ul>
<p>The perfect prediction is recall = 1 &amp; precision = 1.</p>
<p>The bad prediction is recall = 0 &amp; precision = 0.</p>
<p><img src="images/paste-C83C7277.png" width="697" /></p>
<p><img src="images/paste-46CFCBC5.png" /></p>
<p>Accuracy = # times the model is correct / number of predictions -&gt;
<span class="math inline">\(\frac {(correct \hat y)}{predictions}\)</span> or <span class="math inline">\(TP/TN\)</span></p>
<p>We have to be careful with a <strong>unbalanced data set</strong>. This means that
the amount of 0 are much more than the amounts of 1’s or vice verse. If
we are only concerned about the accuracy, it might be that there is a
very low discriminate power.</p>
<p><em>F.e.</em> if a data set has 99 positives and 1 negative, the model could
adopt always classify as positive and it would be accurate 99% of the
time. What is more important, is to identify correctly that 1
observation that is negative.</p>
<p><span class="math inline">\(\hat f(x) = p\)</span></p>
<p>t = threshold if <span class="math inline">\(p &gt; t\)</span> -&gt; Positive (+1) if <span class="math inline">\(p &lt; t\)</span> -&gt; Positive (+1)</p>
<p>if t=0 -&gt; only prediction positive, where TPR = 1, FPR = 1 if t=1 -&gt;
only prediction negative, where TPR = 0, FPR = 0</p>
<p>TPR = # true positives / # positive obs FPR = # false positives / #
negatives obs</p>
</div>
<div id="receiver-operating-characteristics-roc" class="section level3" number="7.6.2">
<h3><span class="header-section-number">7.6.2</span> Receiver Operating Characteristics (ROC)</h3>
<p>ROC is a graphical plot that illustrates the diagnostic ability of a
binary classifier system as its discrimination threshold is varied.</p>
<p><img src="images/paste-46894C12.png" /></p>
<p>A perfect model = green<br />
Random model = orange</p>
<p>The light blue is closer to the perfect model. Therefore, we would
select this model.</p>
<p>AUC = area under the curve</p>
<hr />
</div>
<div id="multi-class-classification" class="section level3" number="7.6.3">
<h3><span class="header-section-number">7.6.3</span> Multi-class classification</h3>
<p>Most models only support binary classification. Some models natively
support multiple classification such as neural networks. However, there
are ways to transforms models to support multi-class classifiers. There
are two methods proposed below:</p>
<p><strong>1 vs 1 method:</strong> <span class="math inline">\(y{A,B,C}\)</span></p>
<ul>
<li><span class="math inline">\(\hat f_{A,B} (x)[A,B]\)</span></li>
<li><span class="math inline">\(\hat f_{B,C} (x)[B,C]\)</span></li>
<li><span class="math inline">\(\hat f_{A,C} (x)[A,C]\)</span></li>
</ul>
<p>After training each model, we use an input (x,y) and predict the
classification: - <span class="math inline">\(\hat f_{A,B} (x)= A\)</span> - <span class="math inline">\(\hat f_{B,C} (x)= B\)</span> -
<span class="math inline">\(\hat f_{A,C} (x)= A\)</span></p>
<p>Which ever group is voted most, will be the one classified. In this
case, we have the most A’s.</p>
<p>Advantage of this method is that the binary classifiers can be of any
type. The drawback is that there are k possible classes. If there are
many, classes, this will be a lot of work.</p>
<p><strong>1 vs All (other) method:</strong> <span class="math inline">\(y{A,B,C}\)</span></p>
<ul>
<li><span class="math inline">\(\hat f_A(x)[A, -A]\)</span> -&gt; <span class="math inline">\(P_a\)</span></li>
<li><span class="math inline">\(\hat f_B(x)[B, -B]\)</span> -&gt; <span class="math inline">\(P_b\)</span></li>
<li><span class="math inline">\(\hat f_C(x)[C, -C]\)</span> -&gt; <span class="math inline">\(P_C\)</span></li>
</ul>
<p>Then we choose the highest probability as it has the highest confidence.</p>
<p>The advantages is that it only needs k classifiers. However, there needs
to be models that outputs probabilities. It is more likely in this
approach that the estimators are more precise to the 1-vs-1
classification. As each model here can be trained on the entire data
set.</p>
<p><img src="images/paste-B6B55442.png" /></p>
</div>
<div id="maximal-margin-classifier" class="section level3" number="7.6.4">
<h3><span class="header-section-number">7.6.4</span> Maximal Margin Classifier</h3>
<p>An easiest model is when there is only one feature with two classes. A
linear classifier can split these classes into two and classify the two
groups perfectly. However, typically there is some overlap where the
variables are not linearly classifiable. Below are examples from both
options:</p>
<p><img src="images/paste-29E76712.png" /></p>
<p>On a two dimensional spaces this looks like:</p>
<p><img src="images/paste-26391CB2.png" /></p>
<p><span class="math inline">\(R^p = H: B_0+B_1X_1+B_2X_2.....B_pX_p=0\)</span></p>
<p>Robustness maximize the “distance” from the 2 classes.</p>
<hr />
</div>
<div id="support-vector-classifier" class="section level3" number="7.6.5">
<h3><span class="header-section-number">7.6.5</span> Support vector classifier</h3>
<p>It is also possible that there is non-linearity where you cannot draw a
hyper plane and draw a line to separate the classes.</p>
<p>If the objection is to still make this separation in a hyper plane,
there has to be some miss-classifications.</p>
<p>For example, the below it might be better to classify the one “outlier”
wrong and keep the linear separator as it might prove better
out-of-sample accuracy. We want to pick up the true plus difference
instead of the noise in the data. therefore, we could use a maximum
margin classified which allows for a few miss-classification. This could
be within a “budget.”</p>
<p><img src="images/paste-CFF70EEB.png" /></p>
<p>Points that are correct classified on the hyper plane, are additionally
further away than the margin and therefore with confidence classified.</p>
<div id="tutorial-support-vector-machines-svm-in-scikit-learn---datacamp" class="section level4" number="7.6.5.1">
<h4><span class="header-section-number">7.6.5.1</span> <img src="http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1526288453/index3_souoaz.png" alt="Tutorial) Support Vector Machines (SVM) in Scikit-learn - DataCamp" /></h4>
<p>We want to associate with a certain variable, <span class="math inline">\(ϵ_1\)</span>. Somewhat like a
penalty of miss-classifying objects.</p>
<ol style="list-style-type: decimal">
<li>Outside of the margin -&gt; Well-classified = <span class="math inline">\(ϵ_1=0\)</span> =
<span class="math inline">\(y_i(….)&gt; M(1-ϵ_i)=M\)</span></li>
<li>Correctly classified but within margin -&gt; Small penalty =
<span class="math inline">\(ϵ_1=[0,1]\)</span> = <span class="math inline">\(y_i(….)&gt; M(1-ϵ_i)[0,1][0,M]\)</span></li>
<li>Miss-classified -&gt; Large penalty = <span class="math inline">\(ϵ_1=1&gt;\)</span> =
<span class="math inline">\(y_i(….)&gt; M(1-ϵ_i)[&lt;0]\)</span></li>
</ol>
<p>The goal is to maximize the margin. Now we calculate:</p>
<p><span class="math inline">\(y_i(\beta_0+\beta_1X_i+....\beta_pX_i&gt; M(1-ϵ_i)\)</span></p>
<p><em>Type 1:</em></p>
<p>If ϵ is 0, the quantity will be larger or equal to M. So if y is larger
than M, it is correctly classified because the distance between y and
the hyper plane is larger than the margin.</p>
<p><em>Type 2:</em></p>
<p>If ϵ is between 0-1, the margin will also be between 0-1. now we cannot
guarantee that the distance between the hyper plane is larger than 1.
Only that it is between 0 and M.</p>
<p><em>Type 3:</em></p>
<p>If ϵ is larger than 1, the M becomes negative. This means that y is a
negative number and cannot be classified correctly. As for example the
real class was positive but the predicted class was negative or vice
verse.</p>
<p>However, we only want to allow for a few of the observations to be
miss-classified to maximize the model.</p>
<p><span class="math inline">\(ϵ_i=0&gt; u_i(....)&gt;M\)</span></p>
<p>Therefore, there will be “budget” Where the sum of the ϵ cannot go above
a certain value. This will be the hyper parameter C.</p>
<p><span class="math inline">\(ϵ_1 +ϵ_2+....+ϵ_m&lt;C\)</span></p>
<p>If C=0, we do not allow for any miss-classification (maximum margin
classifier). If C=small bias will be low but the variance could be
small. The outlier could change the model a lot. If C=large, the bias is
large and variance small. There will be many miss-classification.</p>
<p>Therefore, C is a trade-off of bias and variance. We can use again the
grid search to find the hyper parameter.</p>
</div>
</div>
</div>
<div id="regularization" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Regularization</h2>
<p>When a model has very high variance and we want to reduce it at the
expense of increasing the bias a little bit (Bias trade off). We want to
do this to have a higher <strong>out of sample accuracy</strong> <em>(also for
interpretation we will see it later).</em> The two of the components of the
accuracy of the model: bias square and the variance. Two components we
can have an effect on.</p>
<p>We use Regularization for models that are complex with many parameters
because they extend to exhibit high variance. We will see it in the
context of regression mainly (polynomial normally).</p>
<p>Regularization term = <span class="math inline">\(\alpha R(\beta)\)</span> where $\alpha $ =
hyperparameter.</p>
<p>RIDGE REGULARIZATION (Here I am penalizing a minimization problem, but I
am adding a not negative cost and what I am penalizing is the square, so
if beta is small not penalizing much but if it big, we are penalizing a
lot). This works better if the data is penalized. Doing this, I am
trying to reduce the variance of the parameters and the model.</p>
<p><img src="images/paste-77192149.png" /></p>
<p>VARIANCE DECREASE BUT THE BIAS INCREASE (because with the regularization
term I am finding other parameters than those minimizing the loss
function I am also penalizing large parameters → large penalty). So this
will not perform as good as the other, so there is a trade-off between
variance and bias (alpha can go to extremes, so a good parameter will
stay somewhere in the middle)</p>
<p>Hyperparameter Alpha</p>
<ul>
<li><p>Green line: Variance of the model</p></li>
<li><p>Black Line: Bias square of the model</p></li>
<li><p>Pink line: Mean square error (the total: sum of the other two)</p></li>
</ul>
<p><img src="images/paste-4624A73A.png" /></p>
<p><em>Using logarithm scale</em></p>
<p><u>What happens to the parameters in the model:</u></p>
<p>the possible values for the alpha (-2,5 and use 50 values) then we
create a list of the parameters of my model for each possible value of
alpha. So I have a polynomial model (scale also as logarithmic).</p>
<p>Each line corresponding to a parameter of my model is a polynomial so we
have the linear and the quadratic terms. Here when I increase the
hyperparameter alpha we can see that the parameters are squeezed towards
0. An interesting thing is to count the number of parameters that are
equal to 0 or non 0. How to do that (the number of nonzero)</p>
<p>All will be different from 0. That is why we obtained a flat line for
ridge regularization. So why is this the case and why do we care about
the non zero coefficients?</p>
<p>I want that my models are accurate (that is why we introduced
regularization)) but also due to interpretability. This is a human
factor.</p>
<p>If I find a 0, the feature is not needed to predict good predictions and
vice versa. So we can infer that the feature is not correlated with the
label.</p>
<div id="interpretability" class="section level3" number="7.7.1">
<h3><span class="header-section-number">7.7.1</span> Interpretability</h3>
<p>Is a key feature to help machine learning models in real life.
Interpretability is required in real life and not just having a high
accuracy. We need to know why. Besides, if we select the good features,
it will probably be better. (the features had signal and not notice).
This is called variable selection.</p>
<p>Best subset of variables is a very old problem. Used to obtain the
lowest out of sample loss, → the highest accuracy. F is considering some
features.</p>
<p>If I have p larger than n it will be very difficult to know the noise.
Reducing the number can help despite the ones that we drop are
correlated.</p>
<p>Naive approach: try all subset of possible features.</p>
<ol style="list-style-type: decimal">
<li><p>Forward Heuristic: (Consider the empty set), then the sets with one
feature. Assume that feature 3 is better. So these features will be
fixed for all the procedures, this means that will never get out of
my set F. The same with 2 features and always with 3.  If any of the
values is better, we are going to fix it with the next iteration. At
some point you don’t obtain something better so you stop.</p></li>
<li><p>Backwards stepwise heuristic selection: Which feature to remove. For
example, 3. So if I remove 1 and 3. And when I can’t improve anymore
I take the last combination.</p></li>
</ol>
<p><u><strong>Lasso Regularization</strong></u></p>
<p>We can consider using Lasso regularization. It is a bridge between
regularization and feature selection. Set some parameters in the model
equal to 0. Implicitly it helps in interpretability and indirectly to
variable selection.</p>
<p>I have p + 1 parameters. We penalize the large parameters (positive or
negative) and squeeze them equal to 0.</p>
<p>Using the same as in for ridge, this time when we plot the non zero is
not a straight line as before. There is a point, that increase probably
is because it didn’t find the global optimum. Empirically it’s true that
many parameters are equal to 0. Why does this happen?</p>
<p><strong>RIDGE AND LASSO REGULARIZATION</strong></p>
<p>(Unconstrained minimization problems as betas can take any values.
Remember large betas are penalized and squeezed to 0)</p>
<p>There is an equivalent problem that is constrained (minimization
problem) as we can see below in the image above.</p>
<p>Ridge: All the points inside the blue circle are valid points and
outside not valid as violates the constraint. The Beta * test a good
training MSE = 2 but i cannot accept it. So let’s see 2.1. (light blue
beta*).</p>
<p>Lasso: All the points inside valid and outside not valid. This once has
spiky regios and for that reason, the probability to intersect in one of
the spikes first is very probable. These points have some of the betas=
0. Lasso is more likely to produce optimal parameters where beta is
equal to 0.  </p>
<p><strong>Finally: ISL book:</strong></p>
<p>In general neither of them will dominate the other (ridge and lasso) We
will have to do first <strong>model selection</strong>. In general, we expect lasso
to perform better for low predictors, on the other hand perform better
when there are many predictors. However, the number of predictors is
never known a priori.</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basics-python.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="advanced-statistical-methods.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["R-Summaries.pdf", "R-Summaries.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
